# 神经网络也能解数学题，DeepMind发布千万数学题海数据集

> 原文：[http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650759759&idx=3&sn=9ef067e756f740a09d9bd1503cfec0e8&chksm=871aa631b06d2f271706cad417d2d9fffc4940e7a0e60f305eec966209a890d6d428bcbb2d1f&scene=21#wechat_redirect](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650759759&idx=3&sn=9ef067e756f740a09d9bd1503cfec0e8&chksm=871aa631b06d2f271706cad417d2d9fffc4940e7a0e60f305eec966209a890d6d428bcbb2d1f&scene=21#wechat_redirect)

机器之心报道

**机器之心编辑部**

> 从中学数学到高数微积分，我们需要做大量数学题。知识点看懂了并不算懂，能解题才是王道。那么神经网络是不是也能理解数学题，并解出这些题目呢？因为从数据上来说，数学题也就是一个序列而已，神经网络说不定能将这个序列映射到正确的答案。

为了促进这方面的研究，DeepMind 近日发布了一个新型数据集，包含大量不同类型的数学问题（练习题级别），旨在考察模型的数学学习和代数推理能力。

数据集地址：https://github.com/deepmind/mathematics_dataset

目前该数据集发布了 1.0 版，其每个模块包含 200 万（问题答案）对和 10000 个预生成测试样本，问题的长度限制为 160 字符，答案的长度限制为 30 字符。每个问题类型中的训练数据被分为「容易训练」、「中等训练难度」和「较难训练」三个级别。这允许通过课程来训练模型。

该数据集包含以下类别：

![](../Images/f0ff8234b2b1f9248ec863e650d58460.jpg)

如下所示为该数据集的示例，其中 Question 是待解决的数学题目，Answer 是对应题目的解。这些题目涉及上述多种数学问题，且进行了分级。

![](../Images/6f56f6e0cf749822434642b512607d2f.jpg)*图 1：数据集示例。* 

**什么是神经网络的数学推导能力**

深度学习在模式匹配、机器翻译、强化学习等领域取得了巨大成功。但是，深度模型的稳健性和灵活性远不及人类。它们对陌生环境的泛化能力不足，且易受对抗样本的影响。

人类智能区别于神经模型且优于后者的一个领域是对「代数泛化」对象和实体的离散组合推理。人类在该领域的泛化能力是复杂、多面的，与双语翻译领域的泛化有显著区别。例如，考虑以下数学问题（答案是 −70x − 165）：

![](../Images/0ff1a00a21a9239114a77c04bcaaea97.jpg)

为了解决这个问题，人类需要使用多种认知技能：

*   将字符解析成实体，如数字、算术运算符、变量（加在一起可组成函数）和单词（决定问题是什么）。

*   规划（例如，识别组合顺序正确的函数）。

*   使用子算法进行函数复合（加、乘）。

*   利用工作记忆存储中间值（如复合函数 h(f(x))）。

*   应用所需的规则、变换、过程和定理。

**这个数据集项目提出了什么**

该数据集包含多种不同类型的数学问题。其动机是，模型如果不具备一些代数泛化能力，则很难处理多种数学问题（包括泛化）。

该领域对神经架构分析非常重要。该数据集除了提供大量问题以外，还有多个优势：数学提供了一个自洽的环境；不同问题类型的符号是相同的，这使得该数据集可以轻松扩展；在一个问题上学到的规则和方法通常可用于其他问题。例如，数字加法的规则在哪里都是一样的，且可作为其他问题（如乘法、多项式加法）的「子程序」（subroutine）。能够执行知识迁移的模型会在这个数据集上取得较好的性能，要想解决较难的问题，知识迁移必不可少。

数学本身是一个有趣的领域，尽管解决该数据集中学校级别数学问题的模型没有实际应用，但它们可能会带来更强大的模型，用于解决大量有趣新颖的数学问题。一般来说，用于验证旨在捕捉算术／系统性推理新架构的实验通常来自数学领域，而这并非巧合。因此 DeepMind 希望通过为此类模型提供大规模训练和评估框架，来为数学领域之外的机器推理研究打下坚实的基础。

**贡献**

数据集和泛化测试：该序列到序列数据集包含多种不同类型的数学问题，可用于评估数学推理。DeepMind 还提供了生成代码和预生成问题。

实验和模型分析：DeepMind 研究者执行了实验评估来研究当前最优神经架构的代数能力，证明了这些架构能够很好地处理多种数学问题，但无法处理所有问题类型，此外它们的泛化能力也有待提升。

**这个数据集测试了什么**

在论文中，作者还用该数据集测试了两种主流模型：循环神经网络和 Transformer，它们已经在序列建模问题上展示出当前最优的性能。下图展示了测试使用的 Attention LSTM 与 Transformer，它们都使用编码器-解码器结构建模问题与答案：

![](../Images/28be8871450df06f296b871ec8e28440.jpg)*图 2：Attentional LSTM 与 Transformer 架构。*

下表展示了不同网络架构的 interpolation 和 extrapolation 性能：

![](../Images/9cc10dffebae4d36b03db9fd5842a9fd.jpg)

*图 3：不同模型的准确率，其中 RMC 为关系循环神经网络。*

如上所示，使用带有多个记忆 slot 的 RMC 在性能上并不会有多大帮助，这表示 RMC 很难使用 slot 操作数学实体。而对于带或不带注意力机制的 LSTM，它们的性能也差不多，作者推测注意力机制并没有学习解析数学问题，因此获得的性能提升并不大。最后，Transformer 明显比其它循环神经网络表现更好一些。

**论文：ANALYSING MATHEMATICAL REASONING ABILITIES OF NEURAL MODELS **

![](../Images/29ab5bcd4324de8b66b6d3005405d9ac.jpg)

论文地址：https://arxiv.org/pdf/1904.01557.pdf

作为人类智能的核心能力，数学推理具有一些独特的挑战：我们不是主要依靠经验和证据来理解和解决数学问题，而是基于推断、学习和利用定律、公理和符号操作规则。在本文中，DeepMind 提出了一个评估（并最终设计）神经架构和相似系统的新挑战，开发了一套数学问题，包括以自由格式文本输入/输出形式的问题和答案序列。

数学领域涵盖算术、代数、概率和微积分，其结构化性质使构建训练和测试分割成为可能。该训练和测试分割旨在清晰地阐明不同架构的能力和故障模式，以及评估它们组合与关联知识和学习过程的能力。描述了数据生成过程及其潜在的未来扩展之后，DeepMind 还对来自两种最强序列到序列架构的模型进行了全面分析，并发现了它们在解决数学问题和泛化知识方面的显著差异。*![](../Images/98db554c57db91144fde9866558fb8c3.jpg)*

****本文为机器之心报道，**转载请联系本公众号获得授权****。**

✄------------------------------------------------

**加入机器之心（全职记者 / 实习生）：hr@jiqizhixin.com**

**投稿或寻求报道：**content**@jiqizhixin.com**

**广告 & 商务合作：bd@jiqizhixin.com**