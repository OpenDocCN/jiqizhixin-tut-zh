# 英文教程太难啃？这里有一份TensorFlow2.0中文教程（持续更新中）

> 原文：[http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650761429&idx=1&sn=310c373fdb6dd0509044e42b11b6b740&chksm=871aacabb06d25bdbb4edaada7194656189c8c73e6c4724147c17479acdc78cb661b36c33afe&scene=21#wechat_redirect](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650761429&idx=1&sn=310c373fdb6dd0509044e42b11b6b740&chksm=871aacabb06d25bdbb4edaada7194656189c8c73e6c4724147c17479acdc78cb661b36c33afe&scene=21#wechat_redirect)

机器之心编辑

**机器之心编辑部**

> 今年 3 月份，谷歌在 Tensorflow Developer Summit 2019 大会上发布 TensorFlow 2.0 Alpha 版。作为当前最为流行的深度学习框架，2.0 Alpha 版的正式发布引人关注。近两个月，网上已经出现了大量 TensorFlow 2.0 英文教程。在此文章中，机器之心为大家推荐一个持续更新的中文教程，以便大家学习。

![](../Images/315b4832be704011bd99f7affee18b5d.jpg)虽然，自 TensorFlow 2.0 发布以来，我们总是能够听到「TensorFlow 2.0 就是 keras」、「说的很好，但我用 PyTorch」类似的吐槽。但毋庸置疑，TensorFlow 依然是当前最主流的深度学习框架（感兴趣的读者可查看机器之心文章：[2019 年，TensorFlow 被拉下马了吗？](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650759875&idx=2&sn=e4eacb6126de840085f1165854937c59&chksm=871aa6bdb06d2fababfcd031371db5903f3c440f97808fbb2f2db7d2efee02b441037fc16577&scene=21#wechat_redirect)）。

整体而言，为了吸引用户，TensorFlow 2.0 从简单、强大、可扩展三个层面进行了重新设计。特别是在简单化方面，TensorFlow 2.0 提供更简化的 API、注重 Keras、结合了 Eager execution。

过去一段时间，机器之心为大家编译介绍了部分英文教程，例如：

*   [如何在 TensorFlow 2.0 中构建强化学习智能体](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650755893&idx=5&sn=8bc44613be1939895b1d2dba6bd99ca7&chksm=871a974bb06d1e5df199f005db8807be2a4273884ea7ba38ce369a86188485026b8ba5412918&scene=21#wechat_redirect)

*   [TensorFlow 2.0 到底怎么样？简单的图像分类任务探一探](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650760180&idx=4&sn=1cf7d0e958040b4830dbecfc6505a24d&chksm=871aa78ab06d2e9c294945df513adeea60b216d85523b60e10b21c468c0f974018f7e16d5ac4&scene=21#wechat_redirect)

此文章中，机器之心为大家推荐一个持续更新的中文教程，方便大家更系统的学习、使用 TensorFlow 2.0 ：

*   知乎专栏地址：https://zhuanlan.zhihu.com/c_1091021863043624960

*   Github 项目地址：https://github.com/czy36mengfei/tensorflow2_tutorials_chinese

该教程是 NLP 爱好者 Doit 在知乎上开的一个专栏，由作者从 TensorFlow2.0 官方教程的个人学习复现笔记整理而来。作者将此教程分为了三类：TensorFlow 2.0 基础教程、TensorFlow 2.0 深度学习实践、TensorFlow 2.0 基础网络结构。

以基础教程为例，作者整理了 Keras 快速入门教程、eager 模式、Autograph 等。目前为止，该中文教程已经包含 20 多篇文章，作者还在持续更新中，感兴趣的读者可以 follow。

![](../Images/38f1347d81dad5bfd45dabc4f7aa6341.jpg)

*该中文教程当前目录*

以下是作者整理的「Keras 快速入门」教程内容。

**Keras 快速入门**

Keras 是一个用于构建和训练深度学习模型的高阶 API。它可用于快速设计原型、高级研究和生产。

keras 的 3 个优点： 方便用户使用、模块化和可组合、易于扩展

**1\. 导入 tf.keras**

tensorflow2 推荐使用 keras 构建网络，常见的神经网络都包含在 keras.layer 中 (最新的 tf.keras 的版本可能和 keras 不同)

```py
import tensorflow as tf
from tensorflow.keras import layers
print(tf.__version__)
print(tf.keras.__version__) 
```

**2\. 构建简单模型**

2.1 模型堆叠

最常见的模型类型是层的堆叠：tf.keras.Sequential 模型

```py
model = tf.keras.Sequential()
model.add(layers.Dense(32, activation='relu'))
model.add(layers.Dense(32, activation='relu'))
model.add(layers.Dense(10, activation='softmax')) 
```

2.2 网络配置

tf.keras.layers 中网络配置：

*   activation：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。

*   kernel_initializer 和 bias_initializer：创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 "Glorot uniform" 初始化器。

*   kernel_regularizer 和 bias_regularizer：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。

```py
layers.Dense(32, activation='sigmoid')
layers.Dense(32, activation=tf.sigmoid)
layers.Dense(32, kernel_initializer='orthogonal')
layers.Dense(32, kernel_initializer=tf.keras.initializers.glorot_normal)
layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.01))
layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l1(0.01)) 
```

**3\. 训练和评估**

3.1 设置训练流程

构建好模型后，通过调用 compile 方法配置该模型的学习流程：

```py
model = tf.keras.Sequential()
model.add(layers.Dense(32, activation='relu'))
model.add(layers.Dense(32, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))
model.compile(optimizer=tf.keras.optimizers.Adam(0.001),
             loss=tf.keras.losses.categorical_crossentropy,
             metrics=[tf.keras.metrics.categorical_accuracy]) 
```

3.2 输入 Numpy 数据

```py
import numpy as np

train_x = np.random.random((1000, 72))
train_y = np.random.random((1000, 10))

val_x = np.random.random((200, 72))
val_y = np.random.random((200, 10))

model.fit(train_x, train_y, epochs=10, batch_size=100,
          validation_data=(val_x, val_y)) 
```

3.3tf.data 输入数据

```py
dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))
dataset = dataset.batch(32)
dataset = dataset.repeat()
val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))
val_dataset = val_dataset.batch(32)
val_dataset = val_dataset.repeat()

model.fit(dataset, epochs=10, steps_per_epoch=30,
          validation_data=val_dataset, validation_steps=3) 
```

3.4 评估与预测

```py
test_x = np.random.random((1000, 72))
test_y = np.random.random((1000, 10))
model.evaluate(test_x, test_y, batch_size=32)
test_data = tf.data.Dataset.from_tensor_slices((test_x, test_y))
test_data = test_data.batch(32).repeat()
model.evaluate(test_data, steps=30)
# predict
result = model.predict(test_x, batch_size=32)
print(result) 
```

**4\. 构建高级模型**

4.1 函数式 api

tf.keras.Sequential 模型是层的简单堆叠，无法表示任意模型。使用 Keras 函数式 API 可以构建复杂的模型拓扑，例如：

*   多输入模型，

*   多输出模型，

*   具有共享层的模型（同一层被调用多次），

*   具有非序列数据流的模型（例如，残差连接）。

使用函数式 API 构建的模型具有以下特征：

*   层实例可调用并返回张量。

*   输入张量和输出张量用于定义 tf.keras.Model 实例。

*   此模型的训练方式和 Sequential 模型一样。

```py
input_x = tf.keras.Input(shape=(72,))
hidden1 = layers.Dense(32, activation='relu')(input_x)
hidden2 = layers.Dense(16, activation='relu')(hidden1)
pred = layers.Dense(10, activation='softmax')(hidden2)

model = tf.keras.Model(inputs=input_x, outputs=pred)
model.compile(optimizer=tf.keras.optimizers.Adam(0.001),
             loss=tf.keras.losses.categorical_crossentropy,
             metrics=['accuracy'])
model.fit(train_x, train_y, batch_size=32, epochs=5) 
```

4.2 模型子类化

通过对 tf.keras.Model 进行子类化并定义您自己的前向传播来构建完全可自定义的模型。在 init 方法中创建层并将它们设置为类实例的属性。在 call 方法中定义前向传播

```py
class MyModel(tf.keras.Model):
    def __init__(self, num_classes=10):
        super(MyModel, self).__init__(name='my_model')
        self.num_classes = num_classes
        self.layer1 = layers.Dense(32, activation='relu')
        self.layer2 = layers.Dense(num_classes, activation='softmax')
    def call(self, inputs):
        h1 = self.layer1(inputs)
        out = self.layer2(h1)
        return out

    def compute_output_shape(self, input_shape):
        shape = tf.TensorShapej(input_shape).as_list()
        shape[-1] = self.num_classes
        return tf.TensorShape(shape)

model = MyModel(num_classes=10)
model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),
             loss=tf.keras.losses.categorical_crossentropy,
             metrics=['accuracy'])

model.fit(train_x, train_y, batch_size=16, epochs=5) 
```

4.3 自定义层

通过对 tf.keras.layers.Layer 进行子类化并实现以下方法来创建自定义层：

*   build：创建层的权重。使用 add_weight 方法添加权重。

*   call：定义前向传播。

*   compute_output_shape：指定在给定输入形状的情况下如何计算层的输出形状。或者，可以通过实现 get_config 方法和 from_config 类方法序列化层。

```py
class MyLayer(layers.Layer):
    def __init__(self, output_dim, **kwargs):
        self.output_dim = output_dim
        super(MyLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        shape = tf.TensorShape((input_shape[1], self.output_dim))
        self.kernel = self.add_weight(name='kernel1', shape=shape,
                                   initializer='uniform', trainable=True)
        super(MyLayer, self).build(input_shape)

    def call(self, inputs):
        return tf.matmul(inputs, self.kernel)

    def compute_output_shape(self, input_shape):
        shape = tf.TensorShape(input_shape).as_list()
        shape[-1] = self.output_dim
        return tf.TensorShape(shape)

    def get_config(self):
        base_config = super(MyLayer, self).get_config()
        base_config['output_dim'] = self.output_dim
        return base_config

    @classmethod
    def from_config(cls, config):
        return cls(**config)

model = tf.keras.Sequential(
[
    MyLayer(10),
    layers.Activation('softmax')
])

model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),
             loss=tf.keras.losses.categorical_crossentropy,
             metrics=['accuracy'])

model.fit(train_x, train_y, batch_size=16, epochs=5) 
```

4.4 回调

```py
callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),
    tf.keras.callbacks.TensorBoard(log_dir='./logs')
]
model.fit(train_x, train_y, batch_size=16, epochs=5,
         callbacks=callbacks, validation_data=(val_x, val_y)) 
```

**5 保持和恢复**

5.1 权重保存

```py
model = tf.keras.Sequential([
layers.Dense(64, activation='relu'),
layers.Dense(10, activation='softmax')])

model.compile(optimizer=tf.keras.optimizers.Adam(0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.save_weights('./weights/model')
model.load_weights('./weights/model')
model.save_weights('./model.h5')
model.load_weights('./model.h5') 
```

5.2 保存网络结构

```py
# 序列化成json
import json
import pprint
json_str = model.to_json()
pprint.pprint(json.loads(json_str))
fresh_model = tf.keras.models.model_from_json(json_str)
# 保持为yaml格式  #需要提前安装pyyaml

yaml_str = model.to_yaml()
print(yaml_str)
fresh_model = tf.keras.models.model_from_yaml(yaml_str) 
```

5.3 保存整个模型

```py
model = tf.keras.Sequential([
  layers.Dense(10, activation='softmax', input_shape=(72,)),
  layers.Dense(10, activation='softmax')
])
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.fit(train_x, train_y, batch_size=32, epochs=5)
model.save('all_model.h5')
model = tf.keras.models.load_model('all_model.h5') 
```

**6\. 将 keras 用于 Estimator**

Estimator API 用于针对分布式环境训练模型。它适用于一些行业使用场景，例如用大型数据集进行分布式训练并导出模型以用于生产

```py
model = tf.keras.Sequential([layers.Dense(10,activation='softmax'),
                          layers.Dense(10,activation='softmax')])

model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

estimator = tf.keras.estimator.model_to_estimator(model) 
```

****本文为机器之心编辑，**转载请联系本公众号获得授权****。**

✄------------------------------------------------

**加入机器之心（全职记者 / 实习生）：hr@jiqizhixin.com**

**投稿或寻求报道：**content**@jiqizhixin.com**

**广告 & 商务合作：bd@jiqizhixin.com**