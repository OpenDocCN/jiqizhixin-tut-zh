# 框一下就能从视频隐身，这是现实版的「隐身衣」？

> 原文：[http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650765569&idx=4&sn=6cc03530d51fa0541284f619dbb08259&chksm=871abd7fb06d34690c43cc81b8c26def8184bbba7eb1ead59bd2faa0bf9ecdb2ec5b040b6954&scene=21#wechat_redirect](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650765569&idx=4&sn=6cc03530d51fa0541284f619dbb08259&chksm=871abd7fb06d34690c43cc81b8c26def8184bbba7eb1ead59bd2faa0bf9ecdb2ec5b040b6954&scene=21#wechat_redirect)

机器之心报道

**参与：思源**

> 嗯，我也想在摄像头面前被「框一下」。

只要画个边界框，模型就能自动追踪边界框内的物体，并在视频中隐藏它。最近，这个神奇的项目借助目标检测与图像修复，成功地让模型对视频中的物体视而不见，并通过伪造背景将物体从视频中抹去。

项目地址：https://github.com/zllrunning/video-object-removal

**效果怎么样**

我们先看看效果，左图是原视频，右图是模型擦除行人后的效果。基本上行人定位与追踪是没什么问题的，但比较困难的地方在于图像修复，即将行人那一部分像素删除后，重建合理的背景。

放大来看，如果背景比较简单，例如纯色说少纹理，那么修复效果是挺好的。但是纹理复杂的情况下，图像修复会出现一些问题，例如车道线对不齐等等。但总体来说，这个项目已经有很好的效果了。

![](../Images/2c6f20536937ac486c141ab66112fc82.jpg)

此外，如果我们想获得上面修复的结果，只需要简单地框选目标就能完成。我们可以画一个边界框，然后模型就会处理视频，并将结果输出到 results/inpainting 文件夹中。

![](../Images/958c72d0706bc1e3dcf0cc78c227bdb8.jpg)

**项目怎么用**

项目的安装和使用也是比较简单的，作者还提供了完整的预训练模型。所以我们只需要配置 Python 3.5 和 PyTorch 0.4 就差不多能跑了，当然还得有一块 GPU。

具体而言，我们需要下载 GitHub 项目，然后转到 inpainting 目录下运行 install.sh 脚本，这就完成安装了。我们可以下载 SiamMask 和 Inpainting 两个预训练模型，并放在项目的 cp 文件夹下，然后就可以愉快地测试 Demo 了：

```py
python demo.py --data data/Human6
```

视频文件也是可以直接测试的：

```py
python demo.py --data data/bag.avi
```

上面两个命令行都会对图像或视频进行处理，并保存生成结果。

*   预训练 SiamMask：http://www.robots.ox.ac.uk/~qwang/SiamMask_DAVIS.pth

*   预训练 Inpainting：https://drive.google.com/file/d/1KAi9oQVBaJU9ytr7dYr2WwEcO5NLiJvo/view?usp=sharing

**原理怎么样**

前面介绍过，video-object-removal 主要借鉴了两项工作，即 SiamMask 与 Deep Video Inpainting，它们都是 CVPR 2019 的研究。通过 SiamMask 追踪视频中的目标，并将 Mask 传递给 Deep Video Inpainting，然后模型就能重建最终修复效果了。

**视频实时追踪**

在 SiamMask 中，研究者展示了如何在统一框架下，实时执行视觉追踪与半监督目标分割。在训练完成后，SiamMask 只依赖一个初始化的边界框，就能实时生成未知类别的目标分割掩码，并以每秒 55 帧的速率实时更新掩码。

**论文：Fast Online Object Tracking and Segmentation: A Unifying Approach**

*   论文地址：https://arxiv.org/abs/1812.05050

*   GitHub：https://github.com/foolwood/SiamMask

![](../Images/197b4233c6ead1f2800f08530e437245.jpg)

*SiamMask 的变体示意图，它可以选择 three-branch 的完整版来预测边界框和掩码，也可以选择 two-branch 的版本直接预测掩码。*

![](../Images/99fcb26f68eb704c5ff3cf5b7be34322.jpg)

*SiamMask 的实时分割与追踪效果。*

**视频实时修复**

视频修复旨在利用视频中合理的内容填补被删除的像素，在深度视频修复这篇论文中，研究者提出了一种深度架构来进行快速的视频修复。该模型建立在基于图像的编码器解码器模型上，并从近邻的一些视频帧收集信息，从而合成未知区域的图像内容。研究者表示他们的方法能构建更连贯和合理的视频修复，同时模型的高效性还能让这种修复实时进行。

**论文：Deep Video Inpainting**

*   论文地址：https://arxiv.org/abs/1905.01639

*   GitHub：https://github.com/mcahny/Deep-Video-Inpainting

![](../Images/27fb6fb0cbbaa0cc573ac4d87eaf8f48.jpg)

*深度视频修复网络的整体结构，该网络会利用当前帧 t 以及 t-6、t-3、t+3、t+6 等图像帧的原始信息，从而根据前面的预测结果 Y_t-1 推断当前帧的修复结果 Y_t。**此外，为了获得时序上的连贯性，作者会使用循环 feedback 和 ConvLSTM 模块，并使用 flow 和 warp 两个损失函数。*

![](../Images/f628b3c058e880296b02040d9cf6b6f5.jpg)*Deep Video Inpainting 的效果（无奈的是，视频中的阴影还在）。*****![](../Images/98db554c57db91144fde9866558fb8c3.jpg)******

*参考链接：*
*https://github.com/zllrunning/video-object-removal*

********本****文为机器之心报道，**转载请联系本公众号获得授权****。**

✄------------------------------------------------

**加入机器之心（全职记者 / 实习生）：hr@jiqizhixin.com**

**投稿或寻求报道：**content**@jiqizhixin.com**

**广告 & 商务合作：bd@jiqizhixin.com**