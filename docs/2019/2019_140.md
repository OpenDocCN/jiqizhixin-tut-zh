# Texar-PyTorch：在PyTorch中集成TensorFlow的最佳特性

> 原文：[http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650772959&idx=3&sn=08bbd64acf3ec197e6758d222728d897&chksm=871a51a1b06dd8b7cd45f0b814932292891cabc10e138e4c1d710ecafee9d9d210a4d6b43a5d&scene=21#wechat_redirect](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650772959&idx=3&sn=08bbd64acf3ec197e6758d222728d897&chksm=871a51a1b06dd8b7cd45f0b814932292891cabc10e138e4c1d710ecafee9d9d210a4d6b43a5d&scene=21#wechat_redirect)

机器之心编译

**机器之心编辑部**

> TensorFlow 和 PyTorch 的框架之争愈演愈烈。二者各有优缺点，选择起来需要费一番脑筋。但是，有句话说得好，「小孩子才做选择，成年人全都要」。为此，来自Petuum Inc 和卡内基梅隆大学的研究者开源了一个通用机器学习包——Texar-PyTorch，结合了 TensorFlow 和 PyTorch 中的许多实用功能与特性。

![](../Images/07f875ae8b428e7e1c877c69e71da124.jpg)

项目地址：https://github.com/asyml/texarTexar-PyTorch 对各类不同的机器学习任务有着广泛的支持，尤其是自然语言处理（NLP）和文本生成任务。基于其已有的 TensorFlow 版本，Texar-PyTorch 结合了 TensorFlow 和 PyTorch 中的许多实用功能与特性。同时，Texar-PyTorch 具有高度可定制性，提供了不同抽象层级的 API，以方便新手和经验丰富的用户。Texar-PyTorch 将实用的 TensorFlow (TF) 模块融合进了 PyTorch，显著增强了 PyTorch 现有的功能。这些模块包括：

*   **数据：**内置常用的预处理、创建批次（batching）、迭代、随机打乱方法。所有方法均采取最佳实践，并可以结合缓存与惰性加载达到高效率。该项目也实现了类似 TFRecord 的模块，以支持复杂类型的大型数据集。

*   **模型模块：**丰富的功能和完美的模块化的机器学习（ML）模型，比如统一接口的序列模型，包括用于文本生成的解码器、注意力机制（attention）和 RNN 等。

*   **训练**：开发者基于 TF Estimator 和 keras.Model 的高级 API，设计了更加灵活的训练模块。该模块集模型训练、评估、预测、TensorBoard 可视化于一体，并能与第三方的超参数调优工具完美结合。

**Texar-PyTorch 功能**通过结合 TF 中的最佳特性与 PyTorch 的直观编程模型，Texar-Pytorch 为构建 ML 应用提供全面支持：

*   **最先进的模型构建模块**—搭建 ML 模型就和搭积木一样，你可以随心所欲地替换模型模块。

*   **简单而高效的数据处理**—丰富的内置数据处理模块，适用于常见类型的数据集。用户可以利用简单的接口实现自定义数据处理模块，而无需担心性能问题。

*   **一体化的自定义模型训练模块**—不用再写千篇一律的训练代码，也不用为了简洁而牺牲可拓展性。

代码示例 1 演示了使用 Texar-PyTorch 搭建并训练用于摘要生成或机器翻译的条件GPT-2 模型的完整代码。

![](../Images/987c2f7d159d01edc543507cec4850d1.jpg) *代码示例 1：使用 Texar-PyTorch 搭建并训练条件 GPT-2 模型 (用于摘要生成等任务)。*

**为何选择 Texar?**

*   **同时支持 TensorFlow & PyTorch。**有时，你无法选择使用哪个底层框架，而学习新的工具包就和自己编写一样费时。现在，使用 Texar，你可以在这两个框架中使用几乎相同的接口，只需对代码进行最小限度的更改。两个版本的工具包还能共享下载的预训练模型权重。

*   **一个工具包，覆盖所有自然语言处理任务。**Texar 提供了自然语言处理任务（尤其是文本生成任务）中常用的大多数神经网络模型。图 1 给出了 Texar 各模块的简介。Texar 内置了最先进的预训练模型，同时还包括了数据处理、建模、训练和评估所需的各类实用方法。一切尽在 Texar 掌握中。

*   **方便新手和行家。**无论你是刚刚入门深度学习，还是一名经验丰富的研究员，Texar 都适合你。Texar 提供最先进的内置组件，同时具有足够的灵活性可以自定义。

![](../Images/7abda1efd3fd94eba7505b930fa22811.jpg)*图 1：**Texar 为数据处理、模型架构、损失函数、训练、评估以及一系列先进的预训练 ML/NLP 模型 (例如，BERT, GPT-2 等) 提供了全套的模块。*

接下来将更详细地介绍 Texar-PyTorch 中建模、数据处理和模型训练这三个关键部分。**建模模块**如图 1 所示，Texar-Pytorch 提供了全套的 ML 模块集。通过精心设计的界面，用户可以通过组合模块自由地构建任意模型。下面的实例展示了如何灵活运用模块接口，以满足不同的机器学习算法的需要，如最大似然学习和对抗性学习。此外，Texar 为具有不同专业知识的用户提供多个抽象层级的接口。例如:

*   通过简单地设置解码器参数 decoding_strategy=「train_greedy」，就可以方便地调用常用的解码策略，例如，teacher-forcing 方法。

*   另一方面，用户可以使用 Helper 类进行更复杂的解码策略，例如，用 GumbelSoftmaxHelper 在对抗学习中使用 Gumbel softmax 解码。经验丰富的用户可以进一步定义新的 Helper 类来定制任意解码策略。

![](../Images/37fa528ff1641a338c0ce31aa0339112.jpg) *代码示例 2:构建预训练的 GPT-2 语言模型，使用最大似然学习和对抗学习 (使用 BERT 作为判别器) 进行微调。*

总之，使用 Texar-PyTorch 建模具有以下主要优势:

*   **完美的模块化**—通过简单地插入/交换几个模块，就可以在不同的使用场景之间进行切换。

*   **多层级的接口**—为新手用户提供高层级的简单 API，为专家用户提供底层级的自定义 API。

*   **内置最先进的预训练模块**—BERT, GPT-2, RoBERTa, XLNet 等，用于文本编码、分类、序列标记和生成等任务。

**数据**Texar-Pytorch 的数据模块旨在为任意 ML 和 NLP 任务提供**简单、高效**和**可自定义**的数据处理。结合 Tensorflow tf.data 中的最佳实践，这些模块极大地增强了 Pytorch 内置的 DataLoader 模块：

*   解耦单个实例预处理和批次构建 – 以获得更清晰的程序逻辑和更简便的自定义。

*   基于缓冲区的随机打乱、缓存和惰性加载 – 以提高效率。

*   通用的数据集迭代器 – 无需额外的用户配置。

*   更直观的 APIs – 在项目中获得最佳实践不需要任何专业知识。

**Texar-PyTorch 内置数据模块**对于常见类型的数据集，Texar-Pytorch 已经包含了可以使用的模块，如下图 2 所示。

![](../Images/e7fa26711369787877d0ac353c2f0170.jpg)

*图 2：**Texar-Pytorch 内置大量 ML 和 NLP 任务的数据模块。*特别的是，RecordData 相当于 TensorFlow 著名的 TFRecordData，后者以二进制格式读取文件，从而允许从文本到图像的任意数据类型。太酷了，不是吗？更重要的是 – 它的使用方式与 TFRecordData 类似。下面的例子说明了一切。假设你想运行一个图像描述模型。每个数据示例通常包含一个图像、一个描述和其他元信息。如何使用 Texar-Pytorch 如下。

![](../Images/74034808be92845b33072b330367c690.jpg) *代码示例 3：**使用 Texar-Pytorch RecordData 加载复杂的图像标题数据。*

**创建自定义数据集**用户可以自定义如何处理数据实例和创建批次，而 Texar 将为你处理缓存、惰性处理和迭代。下面的示例说明了这一点。

![](../Images/7e8d403b33387b8aaddd6e11e68fa2ea.jpg)*代码示例 4：对输入文本执行 BPE 分词的自定义数据集。*

**训练器**每当开始一个新的项目时，你是否厌烦了一次又一次地编写训练和评估代码？你是否需要一个 API 来实现自动化训练，并配备日志记录、保存中间模型、可视化和超参数调优功能? 你是否希望 API 灵活适应你的非传统算法，例如，在对抗学习中交替优化多个损失函数？Texar 训练器（Executor）是你的不二选择。Executor 与广泛使用的 TF Estimator 和 tf.keras.Model 类似，但是更加轻量级，更易自定义。为了演示 Executor 的功能，开发者展示了一般的训练代码，并与 Executor 作对比：**假设我们希望在项目中具有以下功能：**

*   每隔 logging_step 次迭代，在命令行、日志文件和 Tensorboard 上记录进度。

*   每隔`validate_steps`次迭代在验证集上评估模型，使用 BLEU 来评估模型性能。

*   如果验证结果有所改善，保存当前模型权重。如果连续`patience`次验证结果都没有改善，那么载入之前存储的模型权重，并调整学习率。

上面的步骤描述了一个很常见的训练循环。以下是一般的训练循环的实例：

![](../Images/b05900373e5a2c49c85f05344a86915e.jpg)*代码示例 5：**典型的手写 train-eval 循环。*

代码非常冗长。当你需要添加或更改一些功能时，事情会变得更加复杂。现在，如果使用 Executors，该代码将是什么样子？

![](../Images/dcb9cfd4904b773cdcce54da013decb8.jpg)*代码示例 6：**使用 Executor 的相同 train-eval 循环。*

Executor 在命令行的输出如下：

![](../Images/b093b815c9280e278da61738ba7d2b0d.jpg)

在这里，你可以看到验证 BLEU 分数是根据已有结果不断更新的。这要归功于 Executor 流处理度量，它允许对度量值进行增量计算。无需等到最后才能看到验证集的结果！
正如我们所见，使用 Executor 的代码结构化更强，可读性更高。它还具有更强的可扩展性：

**问：如果我们还想在每个周期结束后在验证集上评估呢？**

**答：**只需将` validate_every` 更改为：

![](../Images/6932e19683338439f5f69c94b051fdbb.jpg)

**问：如果我们想在调整学习率`early_stop_patience`次后提前停止训练呢？**

**答：**只需将`action_on_plateau`改为：

![](../Images/97c012c554f70bf916f82a479d6669e3.jpg)

**问：如果我们还想测量单词级别的损失呢？**

**答：**只需在`valid_metrics`中添加一个新的度量即可：

![](../Images/1d16c01c8f723513065cb90a493a3063.jpg)

**问：如果我们想要进行超参数调优并多次训练模型，该怎么办？**

**答**：只需为你想要测试的每一组超参数创建 Executor。由于 Executor 负责模型创建之外的所有进程，所以不需要担心消耗额外的内存或意外地保留以前运行的对象。这是一个在 Hyperopt 中使用 Executor 的示例。

**问：如果在每个周期结束后，我们想把当前的模型权重上传到服务器，发送一封电子邮件汇报进度，然后出门去遛狗，该如何操作？**

**答**：很奇怪，但没问题。只需在你选择的条件下注册一个自定义操作，并做你想做的任何事情：

![](../Images/82201e693b0236b2215e16f7508a1109.jpg)

**Texar-TF 与 Texar-PyTorch 互相切换**如果你是 Texar-TF 用户，毫不费力就可切换到 Texar-PyTorch。相比 Texar TensorFlow，Texar PyTorch 具有几乎相同的接口，可以轻松切换底层框架。尽管有类似的接口，但开发者也遵循每个框架的编码风格，这样你无需学习一种新的子语言。为此，他们更改了一些较低层级的可扩展接口，以便紧密匹配对应框架的原生设计。大多数更改都在数据和训练器模块中，但正如你所见，它们非常容易上手。**开始使用 Texar-PyTorch**请访问该项目的 GitHub repository，并按照安装说明进行操作。实用的资源包括：

*   **文档：**该项目对每个模块和功能都有详细的文档。

*   链接：https://texar-pytorch.readthedocs.io/en/latest/

*   **示例：**开发者强烈建议我们查看项目中的示例，以了解在实践中如何使用 Texar。这些示例都有明确的文档记录，涵盖了丰富的用例。

*   链接：https://github.com/asyml/texar-pytorch/blob/master/examples/README.md

*   **ASYML 工具库：**查找到所有 Texar 资源的快速链接。

*   链接：https://asyml.io/

**[机器之心「SOTA模型」](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650770891&idx=1&sn=25bde35991047a997337c8dd25350089&chksm=871a49b5b06dc0a36fc3407e3643550ef97f72b007e67c4f4be250bfd60c9fdc5389624569c0&scene=21#wechat_redirect)****：****22****大领域、127个任务，机器学习 SOTA 研究一网打尽。****[![](../Images/b9b6a80298070cc7bfd0977f3781a267.jpg)](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650770891&idx=1&sn=25bde35991047a997337c8dd25350089&chksm=871a49b5b06dc0a36fc3407e3643550ef97f72b007e67c4f4be250bfd60c9fdc5389624569c0&scene=21#wechat_redirect)**

www.jiqizhixin.com/sota