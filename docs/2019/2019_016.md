# 不要只关注算法与模型，这里有份产品级深度学习开发指南

> 原文：[http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650774755&idx=1&sn=fb97ae881d7b5d1805b3ba4b40e18acc&chksm=871a589db06dd18bc8cca25e614dcd9f7f9adaaccebe32d31d359c3790d7dd976f7c95e9e477&scene=21#wechat_redirect](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650774755&idx=1&sn=fb97ae881d7b5d1805b3ba4b40e18acc&chksm=871a589db06dd18bc8cca25e614dcd9f7f9adaaccebe32d31d359c3790d7dd976f7c95e9e477&scene=21#wechat_redirect)

机器之心报道

**参与：****一鸣、杜伟**

> 深度学习模型距离实际的应用往往还十分遥远，选择合适的工具进行开发、部署和测试十分重要，这份面向互联网产品经理和开发者的技术指南，可以帮助你寻找到合适的解决方案。

众所周知，深度学习模型仅仅只是构建 AI 产品的重要步骤，但并不是全部。一个互联网产品（如 APP）想要集成深度学习能力，往往还需要走完很多设计、开发和测试方面的工作。如何部署深度学习往往成为了系统设计中更关键的问题。近日，GitHub 上有这样一个项目，专门介绍了如何将深度学习算法和模型融入到互联网产品中。项目基本以流程、架构图为主，目前仍在完善中，适合产品经理和开发者学习。项目地址：https://github.com/alirezadir/Production-Level-Deep-Learning**深度学习产品架构概览**训练深度学习模型不及在生产阶段部署算法模型那样困难。如图所示，模型仅仅只是整个系统中的一部分。

![](../Images/1ddf140fa9ae58c422f6f4efa0a25bc9.jpg)

在深度学习模型之前，有配置、服务基础设施、数据获取、特征抽取等步骤，而在其之后则有数据验证、分析、监控、流程管理和机器资源管理等。生产级别的深度学习应用非常复杂。而涉及这些环节的程序、应用、工具和硬件则更加复杂多样，因此需要遵循特定的流程和步骤，选择合适的工具进行项目。

![](../Images/3839705519672269c273609df73def29.jpg)

为了介绍必要的产品构建流程，项目作者将其分为多个部分，包括数据管理、开发训练评估、测试等步骤。**数据管理**
数据管理是产品级深度学习应用需要解决的第一个问题。选择合适的工具，可以保证模型获得稳定、标注正确、平衡的数据。**数据源**怎样获取数据？这是一个常见的问题。通常有以下三种方法：

*   使用公开数据——刚开始构建产品的时候可以使用；

*   数据增强，如图像数据的旋转裁剪等；

*   合成数据；

**数据标注**正确的数据标注对模型的影响非常大，会影响着整个应用的性能。标注数据的工作可以交给人工进行，或使用标注平台辅助。

*   人工标注

*   众包；

*   数据标注公司： FigureEight、雇佣专门的标注人员

*   标注平台：

*   ‍Prodigy ：一个由 Spacy 团队开发者开发的标注工具，使用主动学习，适用于文本和图像数据；

*   HIVE：AI 标注平台，针对图像数据；

*   Supervisely：计算机视觉数据标注平台；

*   Labelbox：计算机视觉标注；

*   Scale：AI 数据平台，适用于计算机视觉和 NLP 领域。

**数据存储**
数据存储则需要选择合适服务器和数据库，方便业务使用。

*   按对象存储：（即将数据存储为二进制数据，包括图像、音频文件和压缩文本）

*   Aamzon S3 

*   Ceph Object Store

*   数据库：（保存存储文件路径、标签和用户活动等信息）

*   Postgres：对大部分应用都适用的数据库，支持 SQL 和无结构 json 文件；

*   数据湖：（用于收集数据库获得不了的特征，如日志）

*   Amazon Redshift

*   特征存储：（保存机器学习的特征）

*   FEAST：基于谷歌云，目前已开源；

*   Michelangelo：Uber 的开源平台；

**版本控制**

*   DVC：开源的机器学习版本控制工具；

*   Pachyderm：数据版本控制；

*   Dolt：SQL 数据库的版本控制；

**处理流程**

*   训练生产级模型时，通常会将不同来源的数据提取出来，包括存储在数据库和对象存储中的数据、日志，以及其他分类器的输出结果；

*   此外，如果不同任务之间有依赖，则需要在上一个任务完成后将其移除出工作流；

*   工作流管理：Airflow

**开发、训练和评估**
在这一阶段，项目开发者需要选择合适的工具，对深度学习模型、应用框架等进行开发。**软件工程**

*   编辑器

*   ‍Vim

*   Emacs

*   VS Code (https://code.visualstudio.com/)

*   有着内置的 git 和 diff 工具，可以通过 ssh 远程打开项目；

*   Jupyter Notebook：适合项目的开始阶段，但是扩展较困难；

*   Streamlit：交互式数据科学工具；

*   开发设备推荐配置

*   对于个人和初创公司：开发用 4 核图灵架构电脑；训练和评估用同样的 4 核带 GPU 的电脑，如果需要运行很多实验，可以购买云服务；

*   对大型公司：开发上每个机器学习工程师都可以配备 4 核图灵架构电脑，或者直接使用 V100 等服务器；训练和评估则购买云服务，并配置合适的运行环境和崩溃处理机制。

**资源管理**

*   资源管理的作用在于向系统中的任务提供计算资源，提高效率；

*   资源管理工具：

*   集群任务管理系统（如 Slurm）；

*   Docker + Kubernetes；

*   Kubeflow；

*   Polyaxon （付费版本）。

**深度学习框架**

*   除非有充分的理由，否则使用 Tensorflow/Keras 或 PyTorch；

*   以下图表表示了不同框架在「开发」到「生产」的程度：

![](../Images/e54a257fd805ef651dbaeaaeb0905ee7.jpg)

**实验管理**开发、训练和评估流程：

*   从简单的方法开始：训练一个小模型，使用小批的数据。如果这一方法可行，则扩展到更大的数据量和模型上，然后进行调参；

*   实验管理工具：

*   Tensorboard；

*   提供机器学习可视化工具；

*   Losswise ：用于深度学习监控；

*   Comet：可以让用户追踪代码、实验和结果；

*   Weights & Biases ：记录并可视化研究的每个细节；

*   MLFlow Tracking：用于记录参数、代码版本、评估指标和输出文件，并可视化结果。

**调参**

调参则是很重要的一个步骤，能让模型发挥更好的效果。

*   Hyperas：Keras 的超参数算子的简单封装，能够提供一个超参范围供开发者调整；

*   SIGOPT ：可扩展的企业级优化平台；

*   Ray-Tune：可扩展的研究平台，能够进行分布式模型选择（主要关注深度学习和深度强化学习）；

*   Sweeps from Weights & Biases：参数不会被开发者显式地定义，而是通过一个机器学习模型进行拟合和学习。

**分布式训练**

*   数据并行：如果迭代时间过长，则使用数据并行（TensorFlow 和 PyTorch 都支持）；

*   模型并行：当模型无法在单个 GPU 上拟合的时候使用；

*   其他解决方案：

*   Ray；

*   Horovod。

**测试和部署**
产品级深度学习的测试和部署需要完成以下几个步骤：**测试和 CI/CD**与传统软件相比，机器学习生产软件需要更加多样化的测试套件：

![](../Images/793f297a901a6695afd8f28c16310f08.jpg)

*   单元和集成测试类型

*   训练系统测试：测试训练管道；

*   验证测试：测试验证集上的预测系统；

*   功能测试：在少数重要的示例上测试预测系统。

*   持续集成：在每次新的代码更改推送到 repo 之后，运行测试；

*   用于持续集成的 SaaS（软件即服务）：

*   CircleCI, Travis；

*   Jenkins, Buildkite。

**网络部署**这里包括预测系统和服务系统：

*   预测系统：处理输入数据和进行预测

*   服务系统（网络服务器）：

*   为预测考虑规模；

*   使用 REST API 来预测 HTTP 请求；

*   调用预测系统做出响应。

*   服务选项：

*   部署到 VMs，并通过添加实例实现扩展

*   作为容器进行部署，并通过编排（orchestration）实现扩展；

*   容器（Docker）

*   容器编排（最流行的 Kubernetes、MESOS 和 Marathon）

*   将代码部署为「无服务器函数」；

*   通过模型服务解决方案进行部署。

模型服务

*   为 ML 模型进行专门的网络部署

*   批量请求 GPU 推理

*   框架（TensorFlow 服务、MXNet 模型服务器、Clipper 和 SaaS 解决方案）

决策制定

*   CPU 推理

*   如果满足需求，则最好选择 CPU 推理；

*   通过添加更多服务器或选择无服务器来实现扩展。

*   GPU 推理

*   TF 服务或 Clipper；

*   自适应批处理是有用的。

**监测**

*   目的：防止宕机、错误等；

*   捕捉服务和数据恶化的问题；

*   测试云供应商的解决方案是否有效。

**在嵌入和移动设备上部署**

*   主要挑战：内存占用和计算约束

*   解决方案

*   量化

*   缩减模型大小（MobileNets）

*   知识蒸馏（DistillBERT）

*   嵌入式和移动端框架：

*   Tensorflow Lite

*   PyTorch Mobile

*   Core ML

*   ML Kit

*   FRITZ

*   OpenVINO

*   模型转换

*   开放神经网络交换（Open Neural Network Exchange，ONNX）：用于深度学习模型的开源格式

**一体化解决方案**

*   Tensorflow Extended (TFX)

*   Michelangelo (Uber)

*   Google Cloud AI Platform

*   Amazon SageMaker

*   Neptune

*   FLOYD

*   Paperspace

*   Determined AI

*   Domino data lab

在这里，作者提供了一张对比图，用于说明不同的技术选型的优劣势。

![](../Images/61fa3747a91e0a930a166f23bc00a6de.jpg)

**「WAIC 开发者·临港人工智能开发者大会」**将于 **2019 年 12 月 6 日-7 日**在**上海临港**举办。本次大会设有主题演讲、开发者工作坊、开发者挑战赛、技术和产业闭门研讨会等环节。邀请全球AI开发者在现场：**听前沿理论+学实战干货+动手挑战赛。**点击**阅读原文**，立即报名。

[![](../Images/1aefad59d3830ec46effbda84c9924e6.jpg)](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650774446&idx=5&sn=e02d482dff130fee729ff41a597d2d29&chksm=871a5fd0b06dd6c66c9ab79dfe0ded1214f4f39fc8d29024b93086f09c86356c6e1546885cc8&scene=21#wechat_redirect)