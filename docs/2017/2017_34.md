# 资源 | 从文本到视觉：各领域最前沿的论文集合

选自 GitHub

**作者：Simon Brugman**

**机器之心编译**

**参与：吴攀**

深度学习已经在语音识别、机器翻译、图像目标检测和聊天机器人等许多领域百花齐放。近日，GitHub 用户 Simon Brugman 发布了一个按任务分类的深度学习论文项目，其按照不同的任务类型列出了一些当前最佳的论文和对起步有用的论文。机器之心对该项目进行了简单的编译介绍并为部分机器之心报道过的论文加上了相关文章的链接。并同时在文后附带了机器之心曾经发布过的其它论文列表，希望能有助于你的学习和研究。

**目录**

1\. 文本

    1.1\. 代码生成（Code Generation）

    1.2\. 情感分析（Sentiment Analysis）

    1.3\. 翻译（Translation）

    1.4\. 分类（Classification）

2\. 视觉

    2.1\. 游戏（Gaming）

    2.2\. 风格迁移（Style Transfer）

    2.3\. 跟踪（Tracking）

    2.4\. 图像分割（Image Segmentation）

    2.5\. 室外的文本识别（Text (in the Wild) Recognition）

    2.6\. 脑机接口（Brain Computer Interfacing）

    2.7\. 自动驾驶汽车（Self-Driving Cars）

    2.8\. 目标识别（Object Recognition）

    2.9\. 标识识别（Logo Recognition）

    2.10\. 超分辨率（Super Resolution）

    2.11\. 姿态估计（Pose Estimation）

    2.12\. 图像描述（Image Captioning）

    2.13\. 图像压缩（Image Compression）

    2.14\. 图像合成（Image Synthesis）

    2.15\. 面部识别（Face Recognition）

3\. 音频

    3.1\. 音频合成（Audio Synthesis）

4\. 其它

    4.1\. 未分类

    4.2\. 正则化（Regularization）

    4.3\. 神经网络压缩（Neural Network Compression）

    4.4\. 优化器（Optimizers）

**文本**

**代码生成（Code Generation）**

1.A Syntactic Neural Model for General-Purpose Code Generation

时间：2017 年 4 月 6 日

地址：https://arxiv.org/pdf/1704.01696

2.RobustFill: Neural Program Learning under Noisy I/O

时间：2017 年 3 月 21 日

地址：https://arxiv.org/pdf/1703.07469

解读：《微软 RobustFill：无需编程语言，让神经网络自动生成程序》

3.DeepCoder: Learning to Write Programs

时间：2016 年 11 月 7 日

地址：https://arxiv.org/pdf/1611.01989

解读：《学界 | 剑桥与微软提交 ICLR 2017 论文提出 DeepCoder：组合其它程序代码生成新程序》

4.Neuro-Symbolic Program Synthesis

时间：2016 年 11 月 6 日

地址：https://arxiv.org/pdf/1611.01855

**情感分析（Sentiment Analysis）**

1.Rationalizing Neural Predictions

时间：2016 年 6 月 13 日

地址：https://arxiv.org/pdf/1606.04155

2.Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank

时间：2013 年 10 月 18 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/recursive-deep-models-for-semantic-compositionality-over-a-sentiment-treebank.pdf

**翻译（Translation）**

1.Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation

时间：2016 年 11 月 14 日

地址：https://arxiv.org/pdf/1611.04558

解读：《[重磅 | 谷歌神经机器翻译再突破：实现高质量多语言翻译和 zero-shot 翻译（附论文）](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650720536&idx=2&sn=1617ed96796bba31f4d6c6749b7579db&chksm=871b0d66b06c8470e86bf243fab1b7710dd8b222ecbfa99d5ac61dac07694542e6d4b6846db8&scene=21#wechat_redirect)》

2.Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation

时间：2016 年 9 月 26 日

地址：https://arxiv.org/pdf/1609.08144

解读：《[重磅 | 谷歌翻译整合神经网络：机器翻译实现颠覆性突破（附论文）](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650722733&idx=4&sn=6e437dbda2795bfa95cd64f82f6c4d7a&chksm=871b15d3b06c9cc5b68f70b42c35cd5823b58780bce6420cd9f4f365e775be47e4a78d61633e&scene=21#wechat_redirect)》

**分类（Classification）**

1.A Simple but Tough-to-Beat Baseline for Sentence Embeddings

时间：2016 年 11 月 4 日

地址：https://openreview.net/pdf?id=SyK00v5xx

2.From Word Embeddings To Document Distances

时间：2016 年 7 月 6 日

地址：http://proceedings.mlr.press/v37/kusnerb15.pdf

3.Character-level Convolutional Networks for Text Classification

时间：2015 年 9 月 4 日

地址：https://arxiv.org/pdf/1509.01626

4.GloVe: Global Vectors for Word Representation

时间：2015 年 5 月 25 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/glove-global-vectors-for-word-representation.pdf

5.Distributed Representations of Sentences and Documents

时间：2014 年 5 月 16 日

地址：https://arxiv.org/pdf/1405.4053

6.Efficient Estimation of Word Representations in Vector Space

时间：2013 年 1 月 16 日

地址：https://arxiv.org/pdf/1301.3781

**视觉**

**游戏（Gaming）**

1.Phase-Functioned Neural Networks for Character Control

时间：2017 年 5 月 1 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/phase-functioned-neural-networks-for-character-control.pdf

2.Equivalence Between Policy Gradients and Soft Q-Learning

时间：2017 年 4 月 21 日

地址：https://arxiv.org/pdf/1704.06440

3.Beating Atari with Natural Language Guided Reinforcement Learning

时间：2017 年 4 月 18 日

地址：https://arxiv.org/pdf/1704.05539

4.Learning from Demonstrations for Real World Reinforcement Learning

时间：2017 年 4 月 12 日

地址：https://arxiv.org/pdf/1704.03732

5.FeUdal Networks for Hierarchical Reinforcement Learning

时间：2017 年 3 月 3 日

地址：https://arxiv.org/pdf/1703.01161

6.Overcoming catastrophic forgetting in neural networks

时间：2016 年 12 月 2 日

地址：https://arxiv.org/pdf/1612.00796

解读：《[为机器赋予记忆：DeepMind 重磅研究提出弹性权重巩固算法](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650724263&idx=1&sn=027a1d2a6f00ec962e9ada8bf8c411aa&chksm=871b13d9b06c9acfde9dbd6bb6647c63839e5e1290ecbcb105507e534e367a725d68bbbb6d78&scene=21#wechat_redirect)》

7.DeepChess: End-to-End Deep Neural Network for Automatic Learning in Chess

时间：2015 年 8 月 16 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/deepchess-end-to-end-deep-neural-network-for-automatic-learning-in-chess.pdf

8.Dueling Network Architectures for Deep Reinforcement Learning

时间：2015 年 11 月 20 日

地址：https://arxiv.org/pdf/1511.06581

9.Human-level control through deep reinforcement learning

时间：2015 年 2 月 26 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/human-level-control-through-deep-reinforcement-learning.pdf

10.Playing Atari with Deep Reinforcement Learning

时间：2013 年 12 月 19 日

地址：https://arxiv.org/pdf/1312.5602

**风格迁移（Style Transfer）**

1.Deep Photo Style Transfer

时间：2017 年 3 月 22 日

地址：https://arxiv.org/pdf/1703.07511

解读：《[资源 | 下一代 PS 工具：Adobe 照片级图像风格转换的 Torch 实现](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650724939&idx=4&sn=0f18b339d0bcb09de1c1efd5cff978a8&chksm=871b1e35b06c972387569f7222f834ad848c63777ed9ae6b0f78ba67a5e55bd63b5f9da8c769&scene=21#wechat_redirect)》

2.Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization

时间：2017 年 3 月 20 日

地址：https://arxiv.org/pdf/1703.06868

开源项目：https://github.com/xunhuang1995/AdaIN-style

3.A Learned Representation For Artistic Style

时间：2016 年 10 月 24 日

地址：https://arxiv.org/pdf/1610.07629

4.Instance Normalization: The Missing Ingredient for Fast Stylization

时间：2016 年 7 月 27 日

地址：https://arxiv.org/pdf/1607.08022

5.Perceptual Losses for Real-Time Style Transfer and Super-Resolution

时间：2016 年 3 月 27 日

地址：https://arxiv.org/pdf/1603.08155

开源项目：http://github.com/jcjohnson/fast-neural-style

6.A Neural Algorithm of Artistic Style

时间：2015 年 8 月 26 日

地址：https://arxiv.org/pdf/1508.06576

开源项目：https://github.com/lengstrom/fast-style-transfer/

**跟踪（Tracking）**

1.End-to-end representation learning for Correlation Filter based tracking

时间：2017 年 4 月 20 日

地址：https://arxiv.org/pdf/1704.06036

开源项目：https://github.com/bertinetto/cfnet

**图像分割（Image Segmentation）**

1.SfM-Net: Learning of Structure and Motion from Video

时间：2017 年 4 月 25 日

地址：https://arxiv.org/pdf/1704.07804

2.Mask R-CNN

时间：2017 年 3 月 20 日

地址：https://arxiv.org/pdf/1703.06870

解读：《[学界 | Facebook 新论文提出通用目标分割框架 Mask R-CNN：更简单更灵活表现更好](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650724526&idx=2&sn=10ccdf74b480da89fce21ca7501718c1&chksm=871b1cd0b06c95c60c0a03580f5a21abd03c06193f1ac67440e6fb69609af5e7b7c029355568&scene=21#wechat_redirect)》和《[深度 | 用于图像分割的卷积神经网络：从 R-CNN 到 Mark R-CNN](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650725842&idx=2&sn=e18500166c6108d7194588befba061a4&chksm=871b19acb06c90ba9c19ba73719d375c4fe1f378f9bccae82e508c34a20c7513c55a84d3441b&scene=21#wechat_redirect)》

3.Learning Features by Watching Objects Move

时间：2016 年 12 月 19 日

地址：https://arxiv.org/pdf/1612.06370

4.Fully Convolutional Networks for Semantic Segmentation

时间：2016 年 5 月 20 日

地址：https://arxiv.org/pdf/1605.06211

5.Instance-aware Semantic Segmentation via Multi-task Network Cascades

时间：2015 年 12 月 14 日

地址：https://arxiv.org/pdf/1512.04412

6.Multi-Scale Context Aggregation by Dilated Convolutions

时间：2015 年 11 月 23 日

地址：https://arxiv.org/pdf/1511.07122

7.SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation

时间：2015 年 11 月 2 日

地址：https://arxiv.org/pdf/1511.00561

8.Learning Rich Features from RGB-D Images for Object Detection and Segmentation

时间：2014 年 7 月 22 日

地址：https://arxiv.org/pdf/1407.5736

**室外的文本识别（Text (in the Wild) Recognition）**

1.OCR Error Correction Using Character Correction and Feature-Based Word Classification

时间：2016 年 4 月 21 日

地址：https://arxiv.org/pdf/1604.06225

2.Recursive Recurrent Nets with Attention Modeling for OCR in the Wild

时间：2016 年 5 月 9 日

地址：https://arxiv.org/pdf/1603.03101

3.COCO-Text: Dataset and Benchmark for Text Detection and Recognition in Natural Images

时间：2016 年 1 月 26 日

地址：https://arxiv.org/pdf/1601.07140

4.Efficient Scene Text Localization and Recognition with Local Character Refinement

时间：2015 年 4 月 14 日

地址：https://arxiv.org/pdf/1504.03522

5.Reading Text in the Wild with Convolutional Neural Networks

时间：2014 年 12 月 4 日

地址：https://arxiv.org/pdf/1412.1842

6.Synthetic Data and Artificial Neural Networks for Natural Scene Text Recognition

时间：2014 年 6 月 9 日

地址：https://arxiv.org/pdf/1406.2227

**脑机接口（Brain Computer Interfacing）**

1.Encoding Voxels with Deep Learning

时间：2015 年 12 月 2 日

地址：http://www.jneurosci.org/content/jneuro/35/48/15769.full.pdf

2，Deep Neural Networks Reveal a Gradient in the Complexity of Neural Representations across the Ventral Stream

时间：2015 年  7 月 8 日

地址：http://www.jneurosci.org/content/jneuro/35/27/10005.full.pdf

**自动驾驶汽车（Self-Driving Cars）**

1.Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art

时间：2017 年 4 月 18 日

地址：https://arxiv.org/pdf/1704.05519

解读：《[重磅 | 自动驾驶计算机视觉研究综述：难题、数据集与前沿成果（附 67 页论文下载）](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650725803&idx=1&sn=0805515d0edd5cf01d2be07b435eb312&chksm=871b19d5b06c90c366c2a873ca1156ae61cef284c52c6bb7127f758f7fbb865748658f678a0f&scene=21#wechat_redirect)》

2.End to End Learning for Self-Driving Cars

时间：2016 年 4 月 25 日

地址：https://arxiv.org/pdf/1604.07316

**目标识别（Object Recognition）**

1.Introspective Classifier Learning: Empower Generatively

时间：2017 年 4 月 25 日

地址：https://arxiv.org/pdf/1704.07816

2.Learning Chained Deep Features and Classifiers for Cascade in Object Detection

时间：2017 年 2 月 23 日

地址：https://arxiv.org/pdf/1702.07054

3.DSSD : Deconvolutional Single Shot Detector

时间：2017 年 1 月 23 日

地址：https://arxiv.org/pdf/1701.06659

4.YOLO9000: Better, Faster, Stronger

时间：2016 年 12 月 25 日

地址：https://arxiv.org/pdf/1612.08242

开源项目：https://github.com/pjreddie/darknet

5.Feature Pyramid Networks for Object Detection

时间：2016 年 12 月 9 日

地址：https://arxiv.org/pdf/1612.03144

6.Speed/accuracy trade-offs for modern convolutional object detectors

时间：2016 年 11 月 30 日

地址：https://arxiv.org/pdf/1611.10012

7.Aggregated Residual Transformations for Deep Neural Networks

时间：2016 年 11 月 16 日

地址：https://arxiv.org/pdf/1611.10012

8.Aggregated Residual Transformations for Deep Neural Networks

时间：2016 年 11 月 16 日

地址：https://arxiv.org/pdf/1611.05431

9.Hierarchical Object Detection with Deep Reinforcement Learning

时间：2016 年 11 月 11 日

地址：https://arxiv.org/pdf/1611.03718

10.Xception: Deep Learning with Depthwise Separable Convolutions

时间：2016 年 10 月 7 日

地址：https://arxiv.org/pdf/1610.02357

11.Learning to Make Better Mistakes: Semantics-aware Visual Food Recognition

时间：2016 年 10 月 1 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/learning-to-make-better-mistakes-semantics-aware-visual-food-recognition.pdf

12.Densely Connected Convolutional Networks

时间：2016 年 8 月 25 日

地址：https://arxiv.org/pdf/1608.06993

13.Residual Networks of Residual Networks: Multilevel Residual Networks

时间：2016 年 8 月 9 日

地址：https://arxiv.org/pdf/1608.02908

14.Context Matters: Refining Object Detection in Video with Recurrent Neural Networks

时间：2016 年 7 月 15 日

地址：https://arxiv.org/pdf/1607.04648

15.R-FCN: Object Detection via Region-based Fully Convolutional Networks

时间：2016 年 5 月 20 日

地址：https://arxiv.org/pdf/1605.06409

16.Training Region-based Object Detectors with Online Hard Example Mining

时间：2016 年 4 月 12 日

地址：https://arxiv.org/pdf/1604.03540

17.T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos

时间：2016 年 4 月 9 日

地址：https://arxiv.org/pdf/1604.02532

18.Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning

时间：2016 年 2 月 23 日

地址：https://arxiv.org/pdf/1602.07261

19.Deep Residual Learning for Image Recognition

时间：2015 年 12 月 10 日

地址：https://arxiv.org/pdf/1512.03385

20.SSD: Single Shot MultiBox Detector

时间：2015 年 12 月 8 日

地址：https://arxiv.org/pdf/1512.02325

21.ParseNet: Looking Wider to See Better

时间：2015 年 6 月 15 日

地址：https://arxiv.org/pdf/1506.04579

22.You Only Look Once: Unified, Real-Time Object Detection

时间：2015 年 6 月 8 日

地址：https://arxiv.org/pdf/1506.02640

23.Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks

时间：2015 年 6 月 4 日

地址：https://arxiv.org/pdf/1506.01497

24.Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification

时间：2015 年 2 月 6 日

地址：https://arxiv.org/pdf/1502.01852

25.Deep Image: Scaling up Image Recognition

时间：2015 年 1 月 13 日

地址：https://arxiv.org/pdf/1501.02876

26.Rich feature hierarchies for accurate object detection and semantic segmentation

时间：2013 年 11 月 11 日

地址：https://arxiv.org/pdf/1311.2524

27.Selective Search for Object Recognition

时间：2013 年 3 月 11 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/selective-search-for-object-recognition.pdf

28.ImageNet Classification with Deep Convolutional Neural Networks

时间：2012 年 12 月 3 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/imagenet-classification-with-deep-convolutional-neural-networks.pdf

**标识识别（Logo Recognition）**

1.Deep Learning Logo Detection with Data Expansion by Synthesising Context

时间：2016 年 12 月 29 日

地址：https://arxiv.org/pdf/1612.09322

2.Automatic Graphic Logo Detection via Fast Region-based Convolutional Networks

时间：2016 年 4 月 20 日

地址：https://arxiv.org/pdf/1604.06083

3.LOGO-Net: Large-scale Deep Logo Detection and Brand Recognition with Deep Region-based Convolutional Networks

时间：2015 年 11 月 8 日

地址：https://arxiv.org/pdf/1511.02462

4.DeepLogo: Hitting Logo Recognition with the Deep Neural Network Hammer

时间：2015 年 10 月 7 日

地址：https://arxiv.org/pdf/1510.02131

**超分辨率（Super Resolution）**

1.Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network

时间：2016 年 9 月 16 日

地址：https://arxiv.org/pdf/1609.05158

2.Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network

时间：2016 年 9 月 15 日

地址：https://arxiv.org/pdf/1609.04802

3.RAISR: Rapid and Accurate Image Super Resolution

时间：2016 年 6 月 3 日

地址：https://arxiv.org/pdf/1606.01299

4.Perceptual Losses for Real-Time Style Transfer and Super-Resolution

时间：2016 年 3 月 27 日

地址：https://arxiv.org/pdf/1603.08155

开源项目：http://github.com/jcjohnson/fast-neural-style

5.Image Super-Resolution Using Deep Convolutional Networks

时间：2014 年 12 月 31 日

地址：https://arxiv.org/pdf/1501.00092

**姿态估计（Pose Estimation）**

1.Forecasting Human Dynamics from Static Images

时间：2017 年 4 月 11 日

地址：https://arxiv.org/pdf/1704.03432

2.Fast Single Shot Detection and Pose Estimation

时间：2016 年 9 月 19 日

地址：https://arxiv.org/pdf/1609.05590

**图像描述（Image Captioning）**

1.Detecting and Recognizing Human-Object Interactions

时间：2017 年 4 月 24 日

地址：https://arxiv.org/pdf/1704.07333

2.Deep Reinforcement Learning-based Image Captioning with Embedding Reward

时间：2017 年 4 月 12 日

地址：https://arxiv.org/pdf/1704.03899

3.Generation and Comprehension of Unambiguous Object Descriptions

时间：2015 年 11 月 7 日

地址：https://arxiv.org/pdf/1511.02283

4.Long-term Recurrent Convolutional Networks for Visual Recognition and Description

时间：2014 年 11 月 17 日

地址：https://arxiv.org/pdf/1411.4389

**图像压缩（Image Compression）**

1.Full Resolution Image Compression with Recurrent Neural Networks

时间：2016 年 8 月 18 日

地址：https://arxiv.org/pdf/1608.05148

解读：《[详解谷歌神经网络图像压缩技术：如何高质量地将图像压缩得更小](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650719511&idx=3&sn=0674ef2a2e995d180ca081ed3a6ae1b9&chksm=871b0169b06c887feefc5604f1f53081e919eadec5c3d02c25d8da786de0bfa23141bd3f184e&scene=21#wechat_redirect)》

**图像合成（Image Synthesis）**

1.A Neural Representation of Sketch Drawings

时间：2017 年 4 月 11 日

地址：https://arxiv.org/pdf/1704.03477

2.BEGAN: Boundary Equilibrium Generative Adversarial Networks

时间：2017 年 3 月 31 日

地址：https://arxiv.org/pdf/1703.10717

开源项目：https://github.com/carpedm20/BEGAN-tensorflow

3.Improved Training of Wasserstein GANs

时间：2017 年 3 月 31 日

地址：https://arxiv.org/pdf/1704.00028

4.Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks

时间：2017 年 3 月 30 日

地址：https://arxiv.org/pdf/1703.10593

开源项目：https://github.com/junyanz/CycleGAN

解读：《[学界 | 让莫奈画作变成照片：伯克利图像到图像翻译新研究](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650725257&idx=4&sn=bf367ff90e03f8189f7c67ae0e5ab76f&chksm=871b1ff7b06c96e1e355d8b360abd0c256af04e2ba72a8d2a3364bfea8ff80b347a734d17e9d&scene=21#wechat_redirect)》

5.RenderGAN: Generating Realistic Labeled Data

时间：2016 年 11 月 4 日

地址：https://arxiv.org/pdf/1611.01331

6.Conditional Image Generation with PixelCNN Decoders

时间：2016 年 6 月 16 日

地址：https://arxiv.org/pdf/1606.05328

7.Pixel Recurrent Neural Networks

时间：2016 年 1 月 25 日

地址：https://arxiv.org/pdf/1601.06759

**面部识别（Face Recognition）**

1.Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition

时间：2016 年 10 月 24 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/accessorize-to-a-crime-real-and-stealthy-attacks-on-state-of-the-art-face-recognition.pdf

2.OpenFace: A general-purpose face recognition library with mobile applications

时间：2016 年 6 月 1 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/openface-a-general-purpose-face-recognition-library-with-mobile-applications.pdf

3.Emotion Recognition in the Wild via Convolutional Neural Networks and Mapped Binary Patterns

时间：2015 年 11 月 9 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/emotion-recognition-in-the-wild-via-convolutional-neural-networks-and-mapped-binary-patterns.pdf

4.Deep Face Recognition

时间：2015 年 9 月 11 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/deep-face-recognition.pdf

5.Compact Convolutional Neural Network Cascade for Face Detection

时间：2015 年 8 月 6 日

地址：https://arxiv.org/pdf/1508.01292

6.Learning Robust Deep Face Representation

时间：2015 年 7 月 17 日

地址：https://arxiv.org/pdf/1507.04844

7.Facenet: A unified embedding for face recognition and clustering

时间：2015 年 6 月 12 日

地址： https://github.com/sbrugman/deep-learning-papers/blob/master/papers/facenet-a-unified-embedding-for-face-recognition-and-clustering.pdf

8.Multi-view Face Detection Using Deep Convolutional Neural Networks

时间：2015 年 2 月 10 日

地址：https://arxiv.org/pdf/1502.02766

**音频**

**音频合成（Audio Synthesis）**

1.A Neural Parametric Singing Synthesizer

时间：2017 年 4 月 12 日

地址：https://arxiv.org/pdf/1704.03809

2.Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders

时间：2017 年 4 月 5 日

地址：https://arxiv.org/pdf/1704.01279

开源项目：https://github.com/tensorflow/magenta/tree/master/magenta/models/nsynth

解读：《[谷歌大脑&DeepMind：NSynth 神经音乐合成器，生成超逼真乐器声音](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650725222&idx=3&sn=f969b59d15b971ee08be734ab57d5947&chksm=871b1f18b06c960ee814d4e4bb658f959991991769d039e29876020db55010de6cff5f6e864c&scene=21#wechat_redirect)》

3.Tacotron: Towards End-to-End Speech Synthesis

时间：2017 年 3 月 29 日

地址：https://arxiv.org/pdf/1703.10135

解读：《[学界 | 谷歌全端到端语音合成系统 Tacotron：直接从字符合成语音](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650725012&idx=5&sn=0a563bffd5f9ca34560767cfb3064e99&chksm=871b1eeab06c97fc74242ddd85fcca962482bd1f76dcd52b139e0a78c4568fdbe08e4b6b3c43&scene=21#wechat_redirect)》

4.Deep Voice: Real-time Neural Text-to-Speech

时间：2017 年 2 月 25 日

地址：https://arxiv.org/pdf/1702.07825

解读：《[业界 | 百度提出 Deep Voice：实时的神经语音合成系统](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650723769&idx=4&sn=7098361f7369fe813aed6b2d035394c8&chksm=871b11c7b06c98d11ff77ed0f23ac56ad1c55ae34756b628f215912f7feb815f290207ab13a6&scene=21#wechat_redirect)》

5.WaveNet: A Generative Model for Raw Audio

时间：2016 年 9 月 12 日

地址：https://arxiv.org/pdf/1609.03499

开源项目：https://github.com/ibab/tensorflow-wavenet

解读：《[重磅 | DeepMind 最新生成模型 WaveNet，将机器合成语音水平与人类差距缩小 50%（附论文）](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650719022&idx=1&sn=3eeb1958e695388817dd32b0d228ced9&scene=21#wechat_redirect)》

**其它**

**未分类**

1.Who Said What: Modeling Individual Labelers Improves Classification

时间：2017 年 3 月 26 日

地址：https://arxiv.org/pdf/1703.08774

2.Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data

时间：2016 年 10 月 18 日

地址：https://arxiv.org/pdf/1610.05755

3.DeepMath - Deep Sequence Models for Premise Selection

时间：2016 年 6 月 14 日

地址：https://arxiv.org/pdf/1606.04442

4.Long Short-Term Memory

时间：1997 年 11 月 15 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/long-short-term-memory.pdf

扩展：《[干货 | 图解 LSTM 神经网络架构及其 11 种变体（附论文）](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650719562&idx=1&sn=ad6693cdeaa18034ed1c53271f642ef7&chksm=871b0134b06c8822bf89781a81081c161eb82b06d0c20b655bd7b991202d363b6c233ef137ff&scene=21#wechat_redirect)》

**正则化（Regularization）**

1.Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning

时间：2015 年 6 月 6 日

地址：https://arxiv.org/pdf/1506.02142

2.Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift

时间：2015 年 2 月 11 日

地址：https://arxiv.org/pdf/1502.03167

**神经网络压缩（Neural Network Compression）**

1.SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size

时间：2016 年 2 月 24 日

地址：https://arxiv.org/pdf/1602.07360

2.Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding

时间：2015 年 10 月 1 日

地址：https://arxiv.org/pdf/1510.00149

**优化器（Optimizers）**

1.Adam: A Method for Stochastic Optimization

时间：2014 年 12 月 22 日

地址：https://arxiv.org/pdf/1412.6980

2.Deep learning with Elastic Averaging SGD

时间：2014 年 12 月 20 日

地址：https://arxiv.org/pdf/1412.6651

3.ADADELTA: An Adaptive Learning Rate Method

时间：2012 年 12 月 22 日

地址：https://arxiv.org/pdf/1212.5701

4.Advances in Optimizing Recurrent Networks

时间：2012 年 12 月 4 日

地址：https://arxiv.org/pdf/1212.0901

5.Efficient Backprop

时间：1998 年 7 月 1 日

地址：https://github.com/sbrugman/deep-learning-papers/blob/master/papers/efficient-backprop.pdf

机器之心发布的其它值得关注的论文和文章列表：

[资源 | 如何开启深度学习之旅？这三大类 125 篇论文为你导航（附资源下载）](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650723904&idx=2&sn=37636b74af0cb3f2d159ca8e336fe4d3&chksm=871b123eb06c9b28a1b31ec4437abeafcaecf23498c9e1a7152cb17a5ad0cdbaf0d84e7816d0&scene=21#wechat_redirect)

[学界 | 2010-2016 年被引用次数最多的深度学习论文（附下载）](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650716071&idx=1&sn=7aa209732425c6a52536fbb9012a09fd&scene=21#wechat_redirect)

[资源 | 生成对抗网络新进展与论文全集](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650725654&idx=3&sn=6bd581c3c442a76f6679ef5df5857a7d&chksm=871b1968b06c907e6428f05237d5d388551ea2328b82c1768464883f23bcd4c566f607c0e1a8&scene=21#wechat_redirect)

[资源 | 生成对抗网络及其变体的论文汇总](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650725730&idx=4&sn=7228767c7688ad8e3802a3978141d499&chksm=871b191cb06c900ae5694a9f102151f483633c09c4892b384abee6055893e3ad35be9d73a31a&scene=21#wechat_redirect)

[人工智能从入门到进阶，机器之心高分技术文章全集](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650722778&idx=1&sn=941eb40c57654222b3e883affa3d08b0&chksm=871b15a4b06c9cb27521a6d22fa1546947c16cd1d620a8816ec37ea3e61bc7f9331ef648f600&scene=21#wechat_redirect)

*原文链接：https://github.com/sbrugman/deep-learning-papers*

**点击阅读原文，报名参与机器之心 GMIS 2017 ↓↓↓**

![](img/b020f33711b628439597b8f9a011b9c1.jpg)