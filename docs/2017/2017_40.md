# 资源 | 生成对抗网络及其变体的论文汇总

选自 Deephunt

**作者：Avinash Hindupur**

**参与：黄小天、蒋思源**

> *生成对抗网络（GAN）是近段时间以来最受研究者关注的机器学习方法之一，深度学习泰斗 Yann LeCun 就曾多次谈到 这种机器学习理念的巨大价值和未来前景。而各类 GAN 的变体也层出不穷，近日机器之心也报道过[生成对抗网络的最新进展与论文集](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650725654&idx=3&sn=6bd581c3c442a76f6679ef5df5857a7d&chksm=871b1968b06c907e6428f05237d5d388551ea2328b82c1768464883f23bcd4c566f607c0e1a8&scene=21#wechat_redirect)，而本文更注重于从 GAN 及其变体的角度对其论文做一个完整的梳理。*

项目地址：https://deephunt.in/the-gan-zoo-79597dc8c347

每一周都会有关于 GAN 的新论文出现，你很难对其一一记录，而众多 GAN 的新命名又使其难上加难。如果你想了解更多关于 GAN 的信息，可参阅 [OpenAI 一篇有关生成模型的博文](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650716227&idx=1&sn=ad2807981602ddabff37d235aa6d2810&scene=21#wechat_redirect)，或者 Goodfellow 于 [NIPS 2016 所做的生成对抗网络主题演讲](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721284&idx=1&sn=427e7f45c8253ab22a3960978409f5d1&chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&scene=21#wechat_redirect)。

因此，下面是一个持续更新的最新列表，通过 GAN 名称+论文（并附 arXiv 论文地址）的形式汇总并编排了所有出现的 GAN：

*   GAN—生成对抗网络（Generative Adversarial Networks）：https://arxiv.org/abs/1406.2661

*   3D-GAN—通过 3D 生成对抗网络建模学习概率性目标形潜在空间（Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling）：https://arxiv.org/abs/1610.07584

*   AdaGAN—AdaGAN：增强生成模型（AdaGAN: Boosting Generative Models）：http://arxiv.org/abs/1701.02386v1

*   AffGAN—图像超分辨率的折旧 MAP 推断（Amortised MAP Inference for Image Super-resolution）：https://arxiv.org/abs/1610.04490

*   ALI—对抗性推断学习（Adversarially Learned Inference）：https://arxiv.org/abs/1606.00704

*   AMGAN—带有最大化激活标注数据的生成对抗网络（Generative Adversarial Nets with Labeled Data by Activation Maximization）：http://arxiv.org/abs/1703.02000v1

*   AnoGAN—使用生成对抗模型的无监督异常检测引导标记的发现（Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery）：http://arxiv.org/abs/1703.05921v1

*   ArtGAN—ArtGAN: 使用条件范畴生成对抗网络合成艺术作品（ArtGAN: Artwork Synthesis with Conditional Categorial GANs）：https://arxiv.org/abs/1702.03410

*   b-GAN—b-GAN: 生成对抗网络的统一架构（b-GAN: Unified Framework of Generative Adversarial Networks）：https://openreview.net/pdf?id=S1JG13oee

*   Bayesian GAN—深度分层隐式模型（Deep and Hierarchical Implicit Models）：https://arxiv.org/abs/1702.08896

*   BEGAN—BEGAN：边界均衡生成对抗网络（BEGAN:Boundary Equilibrium Generative Adversarial Networks）：http://arxiv.org/abs/1703.10717v2

*   BiGAN—对抗性特征学习（Adversarial Feature Learning）：http://arxiv.org/abs/1605.09782v7

*   BS-GAN—边界查找生成对抗网络（Boundary-Seeking Generative Adversarial Networks）：http://arxiv.org/abs/1702.08431v1

*   CGAN—通过条件生成对抗网络实现多样而自然的图像描述（Towards Diverse and Natural Image Descriptions via a Conditional GAN）：http://arxiv.org/abs/1703.06029v1

*   CCGAN—语境条件性生成对抗网络的半监督学习（Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks）：https://arxiv.org/abs/1611.06430v1

*   CatGAN—类属生成对抗网络的无监督和半监督学习（Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks）：http://arxiv.org/abs/1511.06390v2

*   CoGAN—共轭生成对抗网络（Coupled Generative Adversarial Networks）：http://arxiv.org/abs/1606.07536v2

*   Context-RNN-GAN—用于抽象推导图表生成的语境性 RNN-GAN（Contextual RNN-GANs for Abstract Reasoning Diagram Generation）：https://arxiv.org/abs/1609.09444

*   C-RNN-GAN—C-RNN-GAN：对抗训练的连续性循环神经网络（C-RNN-GAN: Continuous recurrent neural networks with adversarial training）：https://arxiv.org/abs/1611.09904

*   CVAE-GAN—CVAE-GAN: 通过非对称训练生成细密纹路的图像（Fine-Grained Image Generation through Asymmetric Training）：https://arxiv.org/abs/1703.10155

*   CycleGAN—使用循环一致性对抗网络进行非成对图到图翻译（Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks）：https://arxiv.org/abs/1703.10593

*   DTN—无监督跨领域图像生成（Unsupervised Cross-Domain Image Generation）：https://arxiv.org/abs/1611.02200

*   DCGAN—使用深度卷积生成对抗网络进行无监督表征学习（Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）：https://arxiv.org/abs/1511.06434

*   DiscoGAN—使用生成对抗网络学习发现跨领域关系（Learning to Discover Cross-Domain Relations with Generative Adversarial Networks）：http://arxiv.org/abs/1703.05192v1

*   DualGAN—DualGAN: 图到图翻译的无监督对偶学习（Unsupervised Dual Learning for Image-to-Image Translation）：http://arxiv.org/abs/1704.02510v1

*   EBGAN—基于能量的生成对抗网络（Energy-based Generative Adversarial Network）：http://arxiv.org/abs/1609.03126v4

*   f-GAN—f-GAN：使用变分散度最小化训练生成式神经采样器（f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization）：https://arxiv.org/abs/1606.00709

*   GoGAN—Gang of GANs: 使用最大间隔排序的生成对抗网络（Generative Adversarial Networks with Maximum Margin Ranking）：https://arxiv.org/abs/1704.04865

*   GP-GAN—GP-GAN: 走近逼真的高分辨率图像混合（Towards Realistic High-Resolution Image Blending）：http://arxiv.org/abs/1703.07195v2

*   IAN—使用自省的对抗性网络进行神经图像编辑（Neural Photo Editing with Introspective Adversarial Networks）：https://arxiv.org/abs/1609.07093

*   iGAN—在自然图像流形上的生成式视觉操作（Generative Visual Manipulation on the Natural Image Manifold）：https://arxiv.org/abs/1609.03552v2

*   IcGAN—图像编辑的可逆条件生成对抗网络（Invertible Conditional GANs for image editing）：https://arxiv.org/abs/1611.06355

*   ID-CGAN- 使用条件生成对抗网络的图像 De-raining（Image De-raining Using a Conditional Generative Adversarial Network）：http://arxiv.org/abs/1701.05957v3

*   Improved GAN—生成对抗网络训练的改进技术（Improved Techniques for Training GANs）：https://arxiv.org/abs/1606.03498

*   InfoGAN—InfoGAN：信息最大化生成对抗网络的可解释性表征学习（InfoGAN:Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets）：http://arxiv.org/abs/1606.03657v1

*   LR-GAN—LR-GAN：用于图像生成的分层递归生成对抗网络（LR-GAN: Layered Recursive Generative Adversarial Networks for Image Generation）：http://arxiv.org/abs/1703.01560v1

*   LSGAN—最小二乘生成对抗网络（Least Squares Generative Adversarial Networks）：http://arxiv.org/abs/1611.04076v3

*   LS-GAN—利普希茨密度上的损失敏感型生成对抗网络（Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities）：http://arxiv.org/abs/1701.06264v5

*   MGAN—使用马尔可夫过程的生成对抗网络预计算实时纹理合成（Precomputed Real-Time Texture Synthesis with Markovian Generative Adversarial Networks）：https://arxiv.org/abs/1604.04382

*   MAGAN—MAGAN: 生成对抗网络的边缘自适应（Margin Adaptation for Generative Adversarial Networks）：http://arxiv.org/abs/1704.03817v1

*   MalGAN—基于生成对抗网络的黑箱攻击的对抗性恶意实例生成（Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN）：http://arxiv.org/abs/1702.05983v1

*   MARTA-GAN—遥感图像的深度无监督表征学习（Deep Unsupervised Representation Learning for Remote Sensing Images）：https://arxiv.org/abs/1612.08879

*   McGAN—McGan: 均值和协方差特征匹配生成对抗网络（Mean and Covariance Feature Matching GAN）：http://arxiv.org/abs/1702.08398v1

*   MedGAN—使用生成对抗网络生成多标注的离散电子健康记录（Generating Multi-label Discrete Electronic Health Records using Generative Adversarial Networks）：http://arxiv.org/abs/1703.06490v1

*   MIX+GAN—生成对抗网络中的泛化与均衡（Generalization and Equilibrium in Generative Adversarial Nets /GANs）：https://arxiv.org/abs/1703.00573v3

*   MPM-GAN—生成对抗网络多智能体的信息传递（Message Passing Multi-Agent GANs）：https://arxiv.org/abs/1612.01294

*   MV-BiGAN—多视角生成对抗网络（Multi-view Generative Adversarial Networks）：http://arxiv.org/abs/1611.02019v1

*   pix2pix—条件对抗网络的图到图翻译（Image-to-Image Translation with Conditional Adversarial Networks）：https://arxiv.org/abs/1611.07004

*   PPGN—即插即用生成网络：在潜在空间中生成条件迭代图像（Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space）：https://arxiv.org/abs/1612.00005

*   PrGAN—从多对象 2D 视角归纳 3D 模型（3D Shape Induction from 2D Views of Multiple Objects）：https://arxiv.org/abs/1612.05872

*   RenderGAN—RenderGAN：生成逼真标注数据（RenderGAN: Generating Realistic Labeled Data）：https://arxiv.org/abs/1611.01331

*   RTT-GAN—可视段落生成的循环主题转换 GAN（Recurrent Topic-Transition GAN for Visual Paragraph Generation）：https://arxiv.org/abs/1703.07022v2

*   SGAN—堆栈 GAN（Stacked Generative Adversarial Networks）：https://arxiv.org/abs/1612.04357v4

*   SGAN—空间 GAN 的纹理合成（Texture Synthesis with Spatial Generative Adversarial Networks）：https://arxiv.org/abs/1611.08207

*   SAD-GAN—SAD-GAN：通过 GAN 合成自动驾驶（SAD-GAN: Synthetic Autonomous Driving using Generative Adversarial Networks）：https://arxiv.org/abs/1611.08788v1

*   SalGAN—SalGAN：通过 GAN 预测视觉显著度（SalGAN: Visual Saliency Prediction with Generative Adversarial Networks）：https://arxiv.org/abs/1701.01081v2

*   SEGAN—SEGAN：语音增强 GAN（SEGAN: Speech Enhancement Generative Adversarial Network）：https://arxiv.org/abs/1703.09452v1

*   SeqGAN—SeqGAN：具有策略梯度的序列 GAN ( SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient)：https://arxiv.org/abs/1609.05473v5

*   SketchGAN—用于草图检索的对抗训练（Adversarial Training For Sketch Retrieval）：https://arxiv.org/abs/1607.02748

*   SL-GAN—半隐 GAN：学习根据属性生成和修改面部图像（Semi-Latent GAN: Learning to generate and modify facial images from attributes）：https://arxiv.org/abs/1704.02166

*   SRGAN—使用一个 GAN 实现图片逼真的单一图像超分辨率（Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network）：https://arxiv.org/abs/1609.04802v3

*   S²GAN—使用风格与结构对抗网络建模生成图像（Generative Image Modeling using Style and Structure Adversarial Networks）：https://arxiv.org/abs/1603.05631v2

*   SSL-GAN—通过语境条件下的 GAN 实现半监督学习（Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks）：https://arxiv.org/abs/1611.06430v1

*   StackGAN—StackGAN：通过堆栈 GAN 合成文本到图片的逼真图像（StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks）：https://arxiv.org/abs/1612.03242v1

*   TGAN—时间 GAN（Temporal Generative Adversarial Nets）：https://arxiv.org/abs/1611.06624v1

*   TAC-GAN—TAC-GAN—文本条件下的辅助生成器 GAN（TAC-GAN—Text Conditioned Auxiliary Classifier Generative Adversarial Network）：https://arxiv.org/abs/1703.06412v2

*   TP-GAN—超越人脸旋转：通过保有正面视图合成打造用于逼真和身份的整体与局部感知 GAN（Beyond Face Rotation: Global and Local Perception GAN for Photorealistic and Identity Preserving Frontal View Synthesis）：https://arxiv.org/abs/1704.04086

*   Triple-GAN—三重 GAN（Triple Generative Adversarial Nets）：https://arxiv.org/abs/1703.02291v2

*   VGAN—作为能量模型变分训练的 GAN（Generative Adversarial Networks as Variational Training of Energy Based Models）：https://arxiv.org/abs/1611.01799

*   VAE-GAN—使用学习的相似性度量进行超像素自编码（Autoencoding beyond pixels using a learned similarity metric）：https://arxiv.org/abs/1512.09300

*   ViGAN—通过变分信息 GAN 生成和编辑图像（Image Generation and Editing with Variational Info Generative AdversarialNetworks）：https://arxiv.org/abs/1701.04568v1

*   WGAN—Wasserstein GAN：https://arxiv.org/abs/1701.07875v2

*   WGAN-GP—Wasserstein GAN 的改进训练（Improved Training of Wasserstein GANs）：https://arxiv.org/abs/1704.00028

*   WaterGAN—WaterGAN：实时校正单目水下图像色彩的无监督生成网络（WaterGAN: Unsupervised Generative Network to Enable Real-time Color Correction of Monocular Underwater Images）：https://arxiv.org/abs/1702.07392v1*![](img/772b30b2a3f8d55dd21a3f1d22cb6891.jpg)*

**机器之心报道 GAN 相关文章**

*   [资源 | 生成对抗网络新进展与论文全集](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650725654&idx=3&sn=6bd581c3c442a76f6679ef5df5857a7d&chksm=871b1968b06c907e6428f05237d5d388551ea2328b82c1768464883f23bcd4c566f607c0e1a8&scene=21#wechat_redirect)

*   [独家 | GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来（附 PPT）](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721284&idx=1&sn=427e7f45c8253ab22a3960978409f5d1&chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&scene=21#wechat_redirect)

*   [人物 | Ian Goodfellow 亲述 GAN 简史：人工智能不能理解它无法创造的东西](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650725442&idx=2&sn=d180b75df02ca9ed7e3149d77729e057&chksm=871b183cb06c912ae1720bd14b587552410660041b821184776c94bdf33c278e7060bd98c2ca&scene=21#wechat_redirect)

*   [干货 | 直观理解 GAN 背后的原理：以人脸图像生成为例](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650723168&idx=2&sn=68b21b815688443a0dd7caa115cc13fa&chksm=871b171eb06c9e085ab0f2223e6bab04d2eecfa430ca071b19d5c377d909d46724269126dbf3&scene=21#wechat_redirect)

*   [专栏 | 看穿机器学习（W-GAN 模型）的黑箱](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650723168&idx=3&sn=41fcf2fb0408c7b6a9b82d55d91c2b9c&chksm=871b171eb06c9e082c4083ff32748104a617e5cb1e6bd4d296b4db431358b8a41f40908ea8a5&scene=21#wechat_redirect)

*   [学界 | 最小二乘 GAN：比常规 GAN 更稳定，比 WGAN 收敛更迅速](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650723893&idx=5&sn=bed0e585bba8ad01824a8d80603dbea6&chksm=871b124bb06c9b5d5f3b290ad02fb43ba02bdf7cbd04d53cfe839213ad7e57c0426555500e24&scene=21#wechat_redirect)

*   [资源 | Wasserstein GAN 的 TensorFlow 实现](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650723201&idx=3&sn=204b20981a52c8e190624e0c0e445857&chksm=871b17ffb06c9ee9b4fc57ea05762dde2f54229f7510c1f60deb7b6707ec3647066aa192a0a5&scene=21#wechat_redirect)

*   [综述 | 一文帮你发现各种出色的 GAN 变体](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650724769&idx=2&sn=6fa540106cf6a5fd55fc39d057092888&chksm=871b1ddfb06c94c9e11d3a8281f60c0fce06a4e021fcd8eaab858c7f08ab9c939c4ad130e4b2&scene=21#wechat_redirect)

*   [一周论文 | GAN（Generative Adversarial Nets）研究进展](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650722118&idx=4&sn=92b16642541dfbc2a154e5c64bf2ffeb&chksm=871b0b38b06c822ea910fa2877a37effa5baf2b7c43107d927d70398a6f0ff7afed99fcf710d&scene=21#wechat_redirect)

*   [学界 | FAIR 提出常见 GAN 训练方法的替代方法：WGAN](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650722818&idx=3&sn=03cb67c8a8ee7f83a7448b518f4336ab&chksm=871b167cb06c9f6a018a99b79d8b2764b207be2b4d03f132151d99124edf2aff4c116a9dc98d&scene=21#wechat_redirect)

******本文为机器之心编译，***转载请联系本公众号获得授权******。***

✄------------------------------------------------

**加入机器之心（全职记者/实习生）：hr@jiqizhixin.com**

**投稿或寻求报道：editor@jiqizhixin.com**

**广告&商务合作：bd@jiqizhixin.com**