# 资源 | NIPS 2016 上 22 篇论文的实现汇集

选自 niut-blanche

**机器之心编译**

**参与：吴攀**

日前，LightOn CEO 兼联合创始人 Igor Carron 在其博客上放出了其收集到的 NIPS 2016 论文的实现（一共 22 个）。他写道：「在 Reddit 上，peterkuharvarduk 决定编译所有来自 NIPS 2016 的可用实现，我很高兴他使用了『实现（ implementation）』这个词，因为这让我可以快速搜索到这些项目。」除了 peterkuharvarduk 的推荐，这里的项目还包括 Reddit 其他用户和 Carron 额外添加的一些新公布的实现。最终他还重点推荐了 GitXiv：http://www.gitxiv.com 。另外，在本文后面还附带了机器之心关于 NIPS 2016 的文章列表，千万不要错过。

 1\. 使用快速权重关注最近的过去（Using Fast Weights to Attend to the Recent Past） 

*   论文：https://arxiv.org/abs/1610.06258

*   GitHub：https://github.com/ajarai/fast-weights

 2\. 通过梯度下降来学习通过梯度下降的学习（Learning to learn by gradient descent by gradient descent）

*   论文：https://arxiv.org/abs/1606.04474

*   GitHub：https://github.com/deepmind/learning-to-learn

 3\. R-FCN：通过基于区域的全卷积网络的目标检测（R-FCN: Object Detection via Region-based Fully Convolutional Networks）

*   论文：https://arxiv.org/abs/1605.06409

*   GitHub：https://github.com/Orpine/py-R-FCN

4\. 用于 k-均值的快速和可证明的 Good Seedings（Fast and Provably Good Seedings for k-Means）

*   论文：https://las.inf.ethz.ch/files/bachem16fast.pdf.

*   GitHub：https://github.com/obachem/kmc2

 5\. 如何训练生成对抗网络（How to Train a GAN）

*   GitHub：https://github.com/soumith/ganhacks

 6\. Phased LSTM：为长的或基于事件的序列加速循环网络训练（Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences）

*   论文：https://arxiv.org/abs/1610.09513

*   GitHub: https://github.com/dannyneil/public_plstm

 7\. 生成对抗式模仿学习（Generative Adversarial Imitation Learning）

*   论文：https://arxiv.org/abs/1606.03476

*   GitHub：https://github.com/openai/imitation

 8\. 对抗式多类分类：一个风险最小化的角度（Adversarial Multiclass Classification: A Risk Minimization Perspective）

*   论文：https://www.cs.uic.edu/~rfathony/pdf/fathony2016adversarial.pdf

*   GitHub：https://github.com/rizalzaf/adversarial-multiclass

 9\. 通过视频预测的用于物理交互的无监督学习（Unsupervised Learning for Physical Interaction through Video Prediction）

*   论文：https://arxiv.org/abs/1605.07157

*   GitHub: https://github.com/tensorflow/models/tree/master/video_prediction

 10.权重规范化：一种加速深度神经网络训练的简单重新参数化（ Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks）

*   论文：https://arxiv.org/abs/1602.07868

*   GitHub：https://github.com/openai/weightnorm

 11\. 全容量整体循环神经网络（Full-Capacity Unitary Recurrent Neural Networks）

*   论文：https://arxiv.org/abs/1611.00035

*   GitHub：https://github.com/stwisdom/urnn

 12\. 带有随机层的序列神经模型（Sequential Neural Models with Stochastic Layers）

*   论文：https://arxiv.org/pdf/1605.07571.pdf

*   GitHub：https://github.com/marcofraccaro/srnn

 13\. 带有快速局部化谱过滤的图上的卷积神经网络（Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering）

*   论文：https://arxiv.org/abs/1606.09375

*   GitHub：https://github.com/mdeff/cnn_graph

 14\. Interpretable Distribution Features with Maximum Testing Power

*   论文：https://papers.nips.cc/paper/6148-interpretable-distribution-features-with-maximum-testing-power.pdf

*   GitHub：https://github.com/wittawatj/interpretable-test/

 15\. 使用神经网络组成图模型，用于结构化表征和快速推理(Composing graphical models with neural networks for structured representations and fast inference )

*   论文：https://arxiv.org/abs/1603.06277

*   GitHub：https://github.com/mattjj/svae

 16\. 使用张量网络的监督学习（Supervised Learning with Tensor Networks）

*   论文：https://arxiv.org/abs/1605.05775

*   GitHub：https://github.com/emstoudenmire/TNML

 17\. 使用贝叶斯条件密度估计的模拟模型的快速无ε推理（Fast ε-free Inference of Simulation Models with Bayesian Conditional Density Estimation）

*   论文：https://arxiv.org/abs/1605.06376

*   GitHub：https://github.com/gpapamak/epsilon_free_inference

 18\. 用于概率程序的贝叶斯优化（Bayesian Optimization for Probabilistic Programs）

*   论文：http://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2016BOPP.pdf

*   GitHub：https://github.com/probprog/bopp

 19\. PVANet：用于实施目标检测的轻权重深度神经网络（PVANet: Lightweight Deep Neural Networks for Real-time Object Detection）

*   论文：https://arxiv.org/abs/1611.08588

*   GitHub：https://github.com/sanghoon/pva-faster-rcnn

 20\. 数据编程：快速创建大训练集（Data Programming: Creating Large Training Sets Quickly）

*   论文：https://arxiv.org/abs/1605.07723

*   代码： snorkel.stanford.edu

 21\. 用于架构学习的卷积神经结构（Convolutional Neural Fabrics for Architecture Learning）

*   论文：https://arxiv.org/pdf/1606.02492.pdf

*   GitHub：https://github.com/shreyassaxena/convolutional-neural-fabrics

 22\. 价值迭代网络（Value Iteration Networks）

*   论文：https://arxiv.org/abs/1602.02867

*   TensorFlow 实现：https://github.com/TheAbhiKumar/tensorflow-value-iteration-networks

*   原作者的 Theano 实现：https://github.com/avivt/VIN

> **机器之心 NIPS 2016 文章列表**
> 
> [深度 | NIPS 2016 最全盘点：主题详解、前沿论文及下载资源（附会场趣闻）](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721406&idx=1&sn=8251dfebd3c360d180339c34c4710fa7&chksm=871b0800b06c81160244fcda78d7816da8ec31d5fbec546ba6e36241e6d32c0ca943ce9ce73d&scene=21#wechat_redirect)
> 
> [独家 | 吴恩达 NIPS 2016 演讲现场直击：如何使用深度学习开发人工智能应用？](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721081&idx=1&sn=d557968703d4af879b5cf6461069dacd&chksm=871b0f47b06c865185865fcd5ef92af7726e84ae9e689b7ced9986a08c9fe3113df296a8469a&scene=21#wechat_redirect)
> 
> [独家 | 机器之心对话 NIPS 2016 最佳论文作者：如何打造新型强化学习观？](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721198&idx=1&sn=accdd701751ab9678285f3cdf073304f&chksm=871b0fd0b06c86c6fa49bbae856898920e26c4456bc02be42a947d23fe2b593110e911bf54da&scene=21#wechat_redirect)
> 
> [独家 | GAN 之父 NIPS 2016 演讲现场直击：全方位解读生成对抗网络的原理及未来](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721284&idx=1&sn=427e7f45c8253ab22a3960978409f5d1&chksm=871b087ab06c816c424ad03810be3e1b3aa9d6e99a5f325047796f110d178a07736f667d1a10&scene=21#wechat_redirect)
> 
> [资源 | Bengio 和 LeCun 在 NIPS 2016 上的演讲](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721325&idx=4&sn=d570f04d737d09c1b1cebd962755af3f&chksm=871b0853b06c8145985f8c2c5ac7445118f18ce35532c0389b0e5ec24a7a1c4b841fe81280de&scene=21#wechat_redirect)
> 
> [学界 | NIPS 2016 公布 571 篇接收论文](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650718527&idx=2&sn=8d054db2eca7a0b25190a6cc050fc1d7&scene=21#wechat_redirect)
> 
> [学界 | NIPS 2016 论文 SpotlightVideo 精选，三分钟了解一项最新研究进展](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721033&idx=2&sn=d0d143e72cf4a637a617be356008b323&chksm=871b0f77b06c86615ed6a59ede1bee6cbff68b6ec08fb9b300e347d9c34b931aabdc3d0fee4e&scene=21#wechat_redirect)
> 
> [学界 | NIPS 2016 现场：谷歌发布 28 篇机器学习论文](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721081&idx=3&sn=111d844d50c98582695d04fa2b252c89&chksm=871b0f47b06c86514ac934c44fe4df92f5d4209f209b94b4c89d1f138492dbaf7e47479803a3&scene=21#wechat_redirect)
> 
> [学界 | DeepMind NIPS 2016 论文盘点（Part1）：强化学习正大步向前](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650720969&idx=2&sn=d1fae404486906125e01b5def7e26d94&chksm=871b0eb7b06c87a1d3e7d0b29e8c8f9e4c86f4949d04b0485df1b45823555a6c88a25ccf4dc4&scene=21#wechat_redirect)
> 
> [学界 | DeepMind NIPS 2016 论文盘点（Part2）：无监督学习的新进展](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721102&idx=2&sn=cbc44a149457d31ed9a8bbe825f09378&chksm=871b0f30b06c8626bb94cbd7a08fd4a5c8bec747082f49280fbd27e9c87c965de983a279796c&scene=21#wechat_redirect)
> 
> [业界 | NIPS 2016 现场：LeCun 联同英伟达，推深度学习教学工具包](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721081&idx=4&sn=af93b221818ff9f564b372de5fc1958f&chksm=871b0f47b06c8651744e4b2819322f4026b248f4474f619c7248f604dafe8490405d70d3d1f3&scene=21#wechat_redirect)
> 
> [业界 | 波士顿动力最新机器人亮相 NIPS 2016，但还未用到机器学习](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650721198&idx=4&sn=b2f6412538b2458116cd40f53bcdc23b&chksm=871b0fd0b06c86c6866c3e682aa9a15187154a67ae4b7df3d319cc2233fb5761c53da45abed1&scene=21#wechat_redirect)
> 
> ***©本文由机器之心编译，***转载请联系本公众号获得授权***。***
> 
> ✄------------------------------------------------
> 
> **加入机器之心（全职记者/实习生）：hr@almosthuman.cn**
> 
> **投稿或寻求报道：editor@almosthuman.cn**
> 
> **广告&商务合作：bd@almosthuman.cn**