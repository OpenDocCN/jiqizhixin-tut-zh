# 资源 | 程序员实用深度学习免费课程：从入门到实践

选自 Course

**机器之心编译**

**参与：李泽南、曹瑞**

> *欢迎来到为期 7 周的「程序员实用深度学习课程，第 1 部分」。这一部分课程由 Jeremy Howard（Kaggel 最初两届比赛冠军选手；Enlitic 的创始人）讲授。在课程中，即使你没有研究生水平的数学背景，也可以学习如何建立最先进的模型，当然这个过程并不简单。最后，最重要的是，这些课程全部都是免费的！*

*   课程官网：http://course.fast.ai/

**做好准备：如何设置亚马逊云服务 (AWS) 深度学习服务器**

*   视频链接：https://www.youtube.com/watch?v=8rjRfW4JM2I

在你开始第一节课之前，你需要一台可以深度学习的机器（也就是说，带有 Nvidia GPU 的计算机）。这部分的课程当中讲述的大部分内容都是以使用亚马逊云服务 (AWS) 为例。

这个视频详细介绍了设置深度学习服务器的各个步骤，使用最近发布的一个叫做「P2」的亚马逊云服务 (AWS) 产品，带有非常强大的 GPU，还有超大内存。

这个视频以及我们大多数的内容，都将 us-west-2 (Oregon) 设置为了默认区域。如果你在欧洲，可以使用 eu-east-1 (Ireland)，使用 setup_p2_ireland.sh，而不是 setup_p2.sh。目前，AWS 的 p2 只在 3 个地区可以使用，如果你在美国或是欧洲以外的其他地方，你还可以使用这些地区的 Amazon 系统映像 (AMI)，但是可能会有延时。

注意：AWS 需要确认用户信息真实性，所以如果你是 AWS 新用户的话，你需要对进入 P2 提出特殊的请求。视频中已经对如何发送这一请求做出了展示，但是要注意的是现在有一点变化：现在你可以直接在表格当中进行请求，在视频中没有显示出来。使用视频中的「use case description」，在你的请求被处理之前，不能设置 P2 服务器。

PS：如果你有 Azure 账户的话，可以用新的 GPU 服务器来代替，它们的运作方式几乎完全相同。如果你希望采用这种方式的话，维基和论坛上面有相关的细节。

**0、为什么要研究深度学习？卷积简介**

*   视频链接：https://www.youtube.com/watch?v=ACU-T9L4_lI

这个课程分为两部分：

*   第一部分为深度学习的高度概述

*   第二部分将简要介绍卷积运算（convolution operation）和随机梯度下降法（Stochastic Gradient Descent）算法

本课的音质的画质与其他课程相比稍差一些。另外，本课当中涉及到的材料在其他的课程当中将会有更加详细地讲述。你在看完第 1 课和第 2 课的视频之后，就会发现事先看这个视频的用处。

**1、识别猫和狗**

*   视频链接：https://www.youtube.com/watch?v=kzt3-FHdAeM

在课程开始之前，请确认已做好深度学习服务器设置，请参阅 AWS 课程：http://course.fast.ai/lessons/aws.html。

在课程开始前，请阅读入门 http://course.fast.ai/start.html。

**概论**

*   视频链接：https://www.youtube.com/watch?v=Th_ckFbc6bI

课程对深度学习进行了简要介绍。随后，我们将展示如何启动、停止和管理 AWS 实例，如何将数据复制到其中（如果你已经熟悉 AWS，那么你可以快速完成这一部分）。

下一部分的讨论的是如何为本课程（以及我们将要处理的所有计算机视觉项目）的数据进行结构化。这是最重要的步骤——如果你的数据有问题，你将无法训练任何模型。

然后进入第一个深度学习模型。我们将学习如何从大量图片中区分猫和狗。我们无需理解数学细节，而是通过学习使用计算机完成任务，使用「微调」，这也许是任何深度学习实践者最重要的技能。一旦我们构建了一个可以从大量猫图中找出狗图的模型，我们就会退后一步，了解最初的「预训练」模型，并验证它在未经任何微调的情况下可以做什么。

**2、卷积神经网络**

*   视频链接：https://www.youtube.com/watch?v=e3aM6XTekJc

在上节课后，你的目标是在区分猫狗的竞赛中达到排名前 50%。在这节课上，Jeremy 将会展示他处理这一任务的作品。

在展示一个成功的模型之后，我们接下来会学到关于分类任务中最常用的损失函数的一些关键信息，同时学习如何使用可视化来了解你的模型的成功和失败之处。

在课程的下半部分，我们将深入了解 CNN 的细节和微调。我们将首先讨论为何通常需要从与训练网络（而不是随机权重）开始，观察微调如何让模型保持层次化，并调节权重以使各层协调。我们将学习为何需要微调，这包括神经网络的三大要素：

*   致密层（或全连接层）

*   随机梯度下降（SGD）

*   激活功能（或非线性）

**3、欠拟合与过拟合**

*   视频链接：https://www.youtube.com/watch?v=6kwQEBMandw

我们已经学到构建 CNN 的几种办法——现在需要全面了解它是如何工作的了。在本节我们详细介绍了卷积的作用，以及它是如何与最大池化（max pooling）一起构建 CNN 的。我们还将了解 softmax 激活函数，它对于在分类模型中获得良好结果是至关重要的（分类模型是设计用于将数据项分为不同类，即离散组的任何模型）。

如果你对于卷积操作不太理解，你可以先跳到第四课的开头。

随后，我们将深入了解创建一个有效模型所需的最重要技能：处理欠拟合与过拟合。首先构建一个过拟合模型（这样我们就会知道我们的模型足够有效，可以被训练），然后逐渐使用一些策略来减少过拟合。在本节中，最重要的部分是应对过拟合的技术列表。我们建议你可以把这份列表抄写到一个方便的地方，随时参考使用，同时确保自己了解其中所有方法的意义。

我们将展示两种应对过拟合最为有用的技术：dropout 和 data augmentation。我们还会讨论预计算卷积层技术。

**4、协同过滤、嵌入**

*   视频链接：https://www.youtube.com/watch?v=V2h3IOBDvrA

卷积是学生最难以理解的概念之一，因此我们将从详细介绍卷积运算开始本节课程，在电子表格中实现一对卷积层和过滤器。接下来，我们对 SGD（和它的新变种）进行相同的介绍，你会看到加速 SGD 方式非常易用。

随后，我们将进一步研究避免过拟合，并学习一些应对含有大量未标记数据，少量已标记数据的数据集（半监督学习任务）的技巧：「伪标记（pseudo-labeling）」与「知识蒸馏（knowledge distillation）」。

最后，我们将离开计算机视觉，对推荐系统（特别是协同过滤）展开讨论，这是一种有用的技术，同时也是了解嵌入概念的好方式。

**5\. 自然语言处理和循环神经网络入门**

*   视频链接：https://www.youtube.com/watch?v=qvRL74L81lg

我们将开始结合我们之前所学过的东西，看我们能从中做出什么东西：我们发现我们得到了一个可以在 Kaggle 上获胜的结果！重点来了：在这个课程中，我们为 VGG 加入了批规范化（batch normalization），而且在原来的教室环境中，我们直接使用这个新实现更新了 VGG16 班。但是，在 MOOC 中，因为每个人都有自己的学习节奏，所以没有提供这个选择——如果你想使用这个版本的批规范化（强烈推荐），我们还创建了一个单独的 Vgg16BN 班。

接下来，让我们回到协同过滤（collaborative filtering），然后我们可以发现我们可以快速轻松地构建一个能极大超越一点快速搜索所能得到的所有基准的模型。然后我们将我们注意力转向了对这些模型所创造的隐因素（latent factor）的可视化。

我们还介绍了一下 Keras 功能 API，后面我们会大量用到它，因为其对架构的构建提供了很好的支持和灵活性。

现在我们终于准备好开始自然语言处理（NLP）了，首先我们会了解前面我们开发的嵌入（embedding）可以如何帮助我们理解自然语言。我们在这个课程中所关注特定 NLP 任务是情感分析（sentiment analysis），但也有明白我们在这里学到的一切也适用于其它 NLP 分类任务（比如：垃圾信息过滤、欺诈检测或假新闻分类、在法律发现中寻找相关文档等）。我们也将了解 NLP 领域中迁移学习的等效技术，即预训练的词向量（pre-trained word vectors）的使用。这个工具能让模型实现更快的训练、减少数据需求、提升泛化能力。

最后我们将介绍循环神经网络（RNN），其中包括了解神经网络架构的「视觉词汇（visual vocabulary）」——后续的课程会用到它们。

**6、构建循环网络**

*   视频链接：https://www.youtube.com/watch?v=ll9y1U0SoVY

本课程首先介绍一个新工具 MixIterator，它允许我们完全实现在前几个课程里学到的伪标记技术（pseudo-labeling technique）。MixIterator 甚至能够进一步改进我们最好的 MNIST 模型，它已进入「学术排行榜」的前五。

然后我们再次在嵌入系统中查看，使用电子表格来显示它们如何在「幕后」工作。我们在嵌入中查看协同过滤（collaborative filterings），就像查看自然语言处理（NLP）那样。

在完成这些较短的任务后，我们就准备开始今天主要的任务，即构建循环神经网络。我们查看循环神经网络各种不同的模型，然后使用基本的 Keras 构建块从头开始创建每个模型。

最后，我们首次查看 Theano，它是 Keras 用来实现计算的库。为了更好地理解 Theano 和循环神经网络的工作原理，我们在纯粹的 Theano 中创建自己的循环神经网络实现。学习 Theano 对于每个人都不是必需的，但是当你发现需要实现在 Keras 中还不存在的东西时，或为你的特定项目修改些什么的时候，Theano 可能就变得至关重要了。它有助于我们理解深度学习真正的运行方式。

**7、卷积神经网络架构；循环神经网络参数推导**

*   视频链接：https://www.youtube.com/watch?v=Q0z-l2KRYFY

这一课是第一部分课程的最后一课！本节分为两个部分：

1.  我们将一起来学习一些新型的卷积神经网络架构，学习如何处理多输入和多输出，如何生成热图，如何处理更大的图像。这些架构都是依赖于 Keras 的 functional API，这我们在上一节课中已经进行了学习，所以在这节课之前一定要确保掌握了这一工具。

2.  我们使用纯 Python 或者是 numpy 建立一个循环神经网络，包括自己进行梯度运算和随机梯度下降（SGD）的更新。之后我们会在 Theano 中建立一个门控循环单元（Gated Recurrent Unit，GRU）。

这些较高级的话题都是进入第 2 部分课程学习的必需内容，第 2 部分课程将于 2017 年 2 月 27 日在旧金山大学数据中心开课，网络课程大约会在 2017 年 3 月更新。之后，我们将会继续对深度学习进行更加全面和深入的探讨，希望这些课程能让你从中受益！

***©本文由机器之心编译，***转载请联系本公众号获得授权***。***

✄------------------------------------------------

**加入机器之心（全职记者/实习生）：hr@almosthuman.cn**

**投稿或寻求报道：editor@almosthuman.cn**

**广告&商务合作：bd@almosthuman.cn**